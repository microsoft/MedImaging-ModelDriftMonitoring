{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from pathlib import Path\r\n",
    "\r\n",
    "import azureml\r\n",
    "from IPython.display import display, Markdown\r\n",
    "from azureml.core import Run, Model\r\n",
    "from azureml.core import Datastore, Experiment, ScriptRunConfig, Workspace, RunConfiguration\r\n",
    "from azureml.core.dataset import Dataset\r\n",
    "from azureml.data import OutputFileDatasetConfig\r\n",
    "from azureml.core.environment import Environment\r\n",
    "from azureml.core.runconfig import DockerConfiguration\r\n",
    "from azureml.exceptions import UserErrorException\r\n",
    "\r\n",
    "from model_drift import settings\r\n",
    "\r\n",
    "# check core SDK version number\r\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Azure ML SDK Version:  1.34.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Connect to workspace\r\n",
    "subscription_id = '9ca8df1a-bf40-49c6-a13f-66b72a85f43c'\r\n",
    "resource_group = 'MLOps-Prototype'\r\n",
    "workspace_name = 'MLOps_shared'\r\n",
    "\r\n",
    "try:\r\n",
    "    ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\r\n",
    "    ws.write_config()\r\n",
    "    print('Library configuration succeeded')\r\n",
    "except:\r\n",
    "    print('Workspace not found')\r\n",
    "\r\n",
    "print(\"Workspace:\", ws.name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Library configuration succeeded\n",
      "Workspace: MLOps_shared\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "## TODO: Incorporate model and model registration into notebook\r\n",
    "\r\n",
    "# experiment_name = 'chexpert-vae-tune'\r\n",
    "# exp = Experiment(workspace=ws, name=experiment_name)\r\n",
    "# for r in exp.get_runs():\r\n",
    "#     if r.display_name  == \"plum_loquat_9kq2qqtn\":\r\n",
    "#         break\r\n",
    "# for run in r.get_children():\r\n",
    "#     if run.display_name == \"wheat_book_mmkzkspg\":\r\n",
    "#         break\r\n",
    "\r\n",
    "# from azureml.core.resource_configuration import ResourceConfiguration\r\n",
    "\r\n",
    "# model = run.register_model(model_name='chexpert-vae-wheat_book_mmkzkspg-049',\r\n",
    "#                            model_path='outputs/checkpoints/last.ckpt/049.ckpt',\r\n",
    "#                            model_framework='PyTorch',\r\n",
    "#                            model_framework_version='1.8',\r\n",
    "#                            description=\"TBD\",\r\n",
    "#                            resource_configuration=ResourceConfiguration(cpu=8, memory_in_gb=2, gpu=True))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "import re\r\n",
    "\r\n",
    "dbg = False\r\n",
    "log_refresh_rate = 1\r\n",
    "\r\n",
    "# Name experiement\r\n",
    "input_dataset_name=\"padchest\"\r\n",
    "experiment_name = 'chexpert-vae-OnPadChest'\r\n",
    "model_name =  \"chexpert-vae-wheat_book_mmkzkspg-049\"\r\n",
    "datastore_name = \"vaeresults_padchest\"\r\n",
    "env_name = \"vae\"\r\n",
    "compute_target = \"nc6-uswest2\"\r\n",
    "compute_target = \"NC24rs-v3-usw2-d\"\r\n",
    "\r\n",
    "\r\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\r\n",
    "environment_file = settings.CONDA_ENVIRONMENT_FILE\r\n",
    "project_dir = Path(\"./experiment\")\r\n",
    "pytorch_env = Environment.from_conda_specification(env_name, file_path =str(environment_file))\r\n",
    "\r\n",
    "pytorch_env.register(workspace=ws)\r\n",
    "build = pytorch_env.build(workspace=ws)\r\n",
    "pytorch_env.environment_variables[\"RSLEX_DIRECT_VOLUME_MOUNT\"] = \"True\"\r\n",
    "pc_dataset = Dataset.get_by_name(ws, name=input_dataset_name)\r\n",
    "datastore = ws.datastores[datastore_name]\r\n",
    "output_dataset_name = re.sub(r'\\W+', \"\" ,f\"{model_name}\".replace('-', \"_\"))\r\n",
    "output_dir =  f\"{output_dataset_name}\"\r\n",
    "\r\n",
    "if dbg:\r\n",
    "    output_dataset_name = f\"{output_dataset_name}_dbg\"\r\n",
    "    output_dir = f\"{output_dir}/dbg\"\r\n",
    "\r\n",
    "output_dir = output_dir.replace(\"//\", \"/\")\r\n",
    "output_dataset = OutputFileDatasetConfig(name=output_dataset_name, destination=(datastore, output_dir.strip(\"/\")+\"/\"))\r\n",
    "\r\n",
    "print(\"Output Dataset Name:\", output_dataset_name)\r\n",
    "print(\"Experiment:\", exp.name)\r\n",
    "print(\"Environment:\", pytorch_env.name)\r\n",
    "\r\n",
    "run_config = RunConfiguration()\r\n",
    "run_config.environment = pytorch_env\r\n",
    "run_config.docker = DockerConfiguration(use_docker=True, shm_size=\"100G\")\r\n",
    "\r\n",
    "run_config.output_data = {\"output_dataset_name\": output_dataset}\r\n",
    "\r\n",
    "\r\n",
    "args = [\r\n",
    "    \"--run_azure\", 1,\r\n",
    "    \"--model\", model_name,\r\n",
    "    '--data_folder', pc_dataset.as_named_input('padchestv1').as_mount(),\r\n",
    "    '--progress_bar_refresh_rate', log_refresh_rate,\r\n",
    "    \"--log_every_n_steps\", log_refresh_rate,\r\n",
    "    \"--flush_logs_every_n_steps\", log_refresh_rate,\r\n",
    "    \"--batch_size\", 128,\r\n",
    "    \"--accelerator\", \"ddp\",\r\n",
    "    \"--output_dir\", output_dataset.as_mount(),\r\n",
    "    \"--write_recon\", 1,\r\n",
    "    \"--write_grid\",  0,\r\n",
    "    ]\r\n",
    "\r\n",
    "if dbg:\r\n",
    "    args += [\r\n",
    "        '--limit_predict_batches', 10,\r\n",
    "        \"--append_run_name\", 1,\r\n",
    "    ]\r\n",
    "\r\n",
    "\r\n",
    "config = ScriptRunConfig(\r\n",
    "    source_directory = str(project_dir), \r\n",
    "    script = \"score.py\",\r\n",
    "    arguments=args,\r\n",
    ")\r\n",
    "run_config.target = compute_target\r\n",
    "config.run_config = run_config\r\n",
    "\r\n",
    "run = exp.submit(config)\r\n",
    "display(Markdown(f\"\"\"\r\n",
    "- Experiement: [{run.experiment.name}]({run.experiment.get_portal_url()})\r\n",
    "- Run: [{run.display_name}]({run.get_portal_url()})\r\n",
    "- Target: {config.run_config.target}\r\n",
    "\"\"\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Output Dataset Name: chexpert_vae_wheat_book_mmkzkspg_049\n",
      "Experiment: chexpert-vae-OnPadChest\n",
      "Environment: vae\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "\n",
       "- Experiement: [chexpert-vae-OnPadChest](https://ml.azure.com/experiments/chexpert-vae-OnPadChest?wsid=/subscriptions/9ca8df1a-bf40-49c6-a13f-66b72a85f43c/resourcegroups/MLOps-Prototype/workspaces/MLOps_shared&tid=72f988bf-86f1-41af-91ab-2d7cd011db47)\n",
       "- Run: [silver_knot_ffzvxdhs](https://ml.azure.com/runs/chexpert-vae-OnPadChest_1633547562_7827089b?wsid=/subscriptions/9ca8df1a-bf40-49c6-a13f-66b72a85f43c/resourcegroups/MLOps-Prototype/workspaces/MLOps_shared&tid=72f988bf-86f1-41af-91ab-2d7cd011db47)\n",
       "- Target: NC24rs-v3-usw2-d\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "# TODO: Move to another notebook or delete?\r\n",
    "\r\n",
    "# experiment_name = \"dataset_debug\"\r\n",
    "# chex_dataset = Dataset.get_by_name(ws, name='chexpert')\r\n",
    "# pc_dataset = Dataset.get_by_name(ws, name=input_dataset_name)\r\n",
    "\r\n",
    "\r\n",
    "# exp = Experiment(workspace=ws, name=experiment_name)\r\n",
    "# environment_file = settings.CONDA_ENVIRONMENT_FILE\r\n",
    "# project_dir = Path(\"./experiment\")\r\n",
    "# pytorch_env = Environment.from_conda_specification(env_name, file_path =str(environment_file))\r\n",
    "\r\n",
    "# pytorch_env.register(workspace=ws)\r\n",
    "# build = pytorch_env.build(workspace=ws)\r\n",
    "\r\n",
    "# pytorch_env.environment_variables[\"RSLEX_DIRECT_VOLUME_MOUNT\"] = \"True\"\r\n",
    "\r\n",
    "# print(\"Experiment:\", exp.name)\r\n",
    "# print(\"Environment:\", pytorch_env.name)\r\n",
    "\r\n",
    "# run_config = RunConfiguration()\r\n",
    "# run_config.environment = pytorch_env\r\n",
    "# run_config.docker = DockerConfiguration(use_docker=True, shm_size=\"100G\")\r\n",
    "\r\n",
    "# args = [\r\n",
    "#     '--data1', pc_dataset.as_named_input('padchestv1').as_mount(),\r\n",
    "#     '--data2', chex_dataset.as_named_input('chexpertv1').as_mount(),\r\n",
    "#     ]\r\n",
    "\r\n",
    "\r\n",
    "# config = ScriptRunConfig(\r\n",
    "#     source_directory = str(project_dir), \r\n",
    "#     script = \"dataset_test.py\",\r\n",
    "#     arguments=args,\r\n",
    "# )\r\n",
    "\r\n",
    "# config.run_config = run_config\r\n",
    "\r\n",
    "# config.run_config.target = compute_target\r\n",
    "\r\n",
    "# # config.run_config.target = \"nc6-uswest2\"\r\n",
    "\r\n",
    "# run = exp.submit(config)\r\n",
    "# display(Markdown(f\"\"\"\r\n",
    "# - Experiement: [{run.experiment.name}]({run.experiment.get_portal_url()})\r\n",
    "# - Run: [{run.display_name}]({run.get_portal_url()})\r\n",
    "# - Target: {config.run_config.target}\r\n",
    "# \"\"\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Experiment: dataset_debug\n",
      "Environment: vae\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "\n",
       "- Experiement: [dataset_debug](https://ml.azure.com/experiments/dataset_debug?wsid=/subscriptions/9ca8df1a-bf40-49c6-a13f-66b72a85f43c/resourcegroups/MLOps-Prototype/workspaces/MLOps_shared&tid=72f988bf-86f1-41af-91ab-2d7cd011db47)\n",
       "- Run: [dreamy_school_t7mkvb9q](https://ml.azure.com/runs/dataset_debug_1633542663_b1d850e4?wsid=/subscriptions/9ca8df1a-bf40-49c6-a13f-66b72a85f43c/resourcegroups/MLOps-Prototype/workspaces/MLOps_shared&tid=72f988bf-86f1-41af-91ab-2d7cd011db47)\n",
       "- Target: nc6-uswest2\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit (conda)"
  },
  "interpreter": {
   "hash": "40209cfd1e49aba1e20a3908f9a243f43b2ed73034fd3a81730d62124bbdcdae"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}