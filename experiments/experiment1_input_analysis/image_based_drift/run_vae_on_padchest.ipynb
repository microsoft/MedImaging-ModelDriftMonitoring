{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import azureml\n",
    "from IPython.display import display, Markdown\n",
    "from azureml.core import Run, Model\n",
    "from azureml.core import Datastore, Experiment, ScriptRunConfig, Workspace, RunConfiguration\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.data import OutputFileDatasetConfig\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "from azureml.exceptions import UserErrorException\n",
    "\n",
    "from model_drift import settings, helpers\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to workspace\n",
    "ws = Workspace.from_config(settings.AZUREML_CONFIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "dbg = True\n",
    "log_refresh_rate = 1\n",
    "\n",
    "# Name experiement\n",
    "input_dataset_name=\"padchest\"\n",
    "experiment_name = 'vae-padchest'\n",
    "if dbg:\n",
    "    experiment_name += '-dbg'\n",
    "model_name = 'vae-padchest-trained-frosty_dinner_h4n3bv0k-049.ckpt'\n",
    "model_name = 'vae-padchest-trained-lime_night_wlbcf6py-049.ckpt'\n",
    "datastore_name = \"results\"\n",
    "env_name = \"vae\"\n",
    "\n",
    "# model = Model(ws, model_name)\n",
    "\n",
    "#Experiment\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "\n",
    "#Environment\n",
    "environment_file = settings.CONDA_ENVIRONMENT_FILE\n",
    "project_dir = settings.SRC_DIR\n",
    "pytorch_env = Environment.from_conda_specification(env_name, file_path =str(environment_file))\n",
    "pytorch_env.register(workspace=ws)\n",
    "build = pytorch_env.build(workspace=ws)\n",
    "pytorch_env.environment_variables[\"AZUREML_COMPUTE_USE_COMMON_RUNTIME\"] = \"false\"\n",
    "pytorch_env.environment_variables[\"RSLEX_DIRECT_VOLUME_MOUNT\"] = \"True\"\n",
    "\n",
    "# Run Configuration\n",
    "run_config = RunConfiguration()\n",
    "run_config.environment_variables[\"AZUREML_COMPUTE_USE_COMMON_RUNTIME\"] = \"false\"\n",
    "run_config.environment_variables[\"RSLEX_DIRECT_VOLUME_MOUNT\"] = \"True\"\n",
    "run_config.environment = pytorch_env\n",
    "run_config.docker = DockerConfiguration(use_docker=True, shm_size=\"100G\")\n",
    "\n",
    "# Input Dataset\n",
    "dataset = Dataset.get_by_name(ws, name=input_dataset_name)\n",
    "datastore = ws.datastores[datastore_name]\n",
    "\n",
    "output_dataset_name = re.sub(r'\\W+', \"\", f\"{model_name}\".replace('-', \"_\"))\n",
    "\n",
    "output_dir = f\"model_outputs/{output_dataset_name}\"\n",
    "\n",
    "if dbg:\n",
    "    output_dir = f\"model_outputs/dbg/{output_dataset_name}\"\n",
    "    output_dataset_name = f\"{output_dataset_name}_dbg\"\n",
    "\n",
    "output_dir = output_dir.replace(\"//\", \"/\")\n",
    "output_dataset = OutputFileDatasetConfig(name=output_dataset_name, destination=(datastore, output_dir.strip(\"/\")+\"/\"))\n",
    "\n",
    "args = {\n",
    "'run_azure': 1,\n",
    " 'model': model_name,\n",
    " 'data_folder': dataset.as_named_input('dataset').as_mount(),\n",
    " 'progress_bar_refresh_rate': 25 if not dbg else 1,\n",
    " 'log_every_n_steps': 25 if not dbg else 1,\n",
    " 'flush_logs_every_n_steps': 25 if not dbg else 1,\n",
    " 'batch_size': 32,\n",
    " 'accelerator': 'ddp',\n",
    " 'output_dir': output_dataset.as_mount(),\n",
    " 'add_name_to_output': int(dbg),\n",
    " 'write_recon': 1\n",
    " }\n",
    "\n",
    "\n",
    "if dbg:\n",
    "    args.update({\n",
    "        'limit_predict_batches': 10,\n",
    "    })\n",
    "\n",
    "for param, value in args.items():\n",
    "    print(f\" {param}: {value}\")\n",
    "\n",
    "print(f\"Environment: {pytorch_env.name}\")\n",
    "print(f\"Experiment: {exp.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_target = \"nc24-uswest2\"\n",
    "\n",
    "config = ScriptRunConfig(\n",
    "    source_directory=str(project_dir),\n",
    "    script=\"scripts/vae/score.py\",\n",
    "    arguments=helpers.argsdict2list(args),\n",
    ")\n",
    "run_config.target = compute_target\n",
    "config.run_config = run_config\n",
    "\n",
    "run = exp.submit(config)\n",
    "display(Markdown(f\"\"\"\n",
    "- Experiment: [{run.experiment.name}]({run.experiment.get_portal_url()})\n",
    "- Run: [{run.display_name}]({run.get_portal_url()})\n",
    "- Target: {config.run_config.target}\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "dbg = True\n",
    "log_refresh_rate = 1\n",
    "\n",
    "# Name experiement\n",
    "input_dataset_name=\"padchest\"\n",
    "experiment_name = 'chexpert-vae-OnPadChest-dbg'\n",
    "model_name =  \"chexpert-vae-wheat_book_mmkzkspg-049\"\n",
    "datastore_name = \"vaeresults_padchest\"\n",
    "env_name = \"vae\"\n",
    "compute_target = \"nc6-uswest2\"\n",
    "compute_target = \"NC24rs-v3-usw2-d\"\n",
    "\n",
    "\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "environment_file = settings.CONDA_ENVIRONMENT_FILE\n",
    "project_dir = Path(\"./experiment\")\n",
    "pytorch_env = Environment.from_conda_specification(env_name, file_path =str(environment_file))\n",
    "\n",
    "pytorch_env.register(workspace=ws)\n",
    "build = pytorch_env.build(workspace=ws)\n",
    "pytorch_env.environment_variables[\"RSLEX_DIRECT_VOLUME_MOUNT\"] = \"True\"\n",
    "pc_dataset = Dataset.get_by_name(ws, name=input_dataset_name)\n",
    "\n",
    "datastore = ws.datastores[datastore_name]\n",
    "output_dataset_name = re.sub(r'\\W+', \"\" ,f\"{model_name}\".replace('-', \"_\"))\n",
    "output_dir =  f\"{output_dataset_name}\"\n",
    "\n",
    "if dbg:\n",
    "    output_dataset_name = f\"{output_dataset_name}_dbg\"\n",
    "    output_dir = f\"{output_dir}/dbg\"\n",
    "\n",
    "output_dir = output_dir.replace(\"//\", \"/\")\n",
    "output_dataset = OutputFileDatasetConfig(name=output_dataset_name, destination=(datastore, output_dir.strip(\"/\")+\"/\"))\n",
    "\n",
    "print(\"Output Dataset Name:\", output_dataset_name)\n",
    "print(\"Experiment:\", exp.name)\n",
    "print(\"Environment:\", pytorch_env.name)\n",
    "\n",
    "run_config = RunConfiguration()\n",
    "run_config.environment = pytorch_env\n",
    "run_config.docker = DockerConfiguration(use_docker=True, shm_size=\"100G\")\n",
    "\n",
    "run_config.output_data = {\"output_dataset_name\": output_dataset}\n",
    "\n",
    "\n",
    "args = [\n",
    "    \"--run_azure\", 1,\n",
    "    \"--model\", model_name,\n",
    "    '--data_folder', pc_dataset.as_named_input('padchestv1').as_mount(),\n",
    "    '--progress_bar_refresh_rate', log_refresh_rate,\n",
    "    \"--log_every_n_steps\", log_refresh_rate,\n",
    "    \"--flush_logs_every_n_steps\", log_refresh_rate,\n",
    "    \"--batch_size\", 128,\n",
    "    \"--accelerator\", \"ddp\",\n",
    "    \"--output_dir\", output_dataset.as_mount(),\n",
    "    \"--write_recon\", 1,\n",
    "    \"--write_grid\",  1,\n",
    "    \"--latent_output_dir\", \"./outputs/\",\n",
    "    \"--append_run_name\", 1,\n",
    "    ]\n",
    "\n",
    "if dbg:\n",
    "    args += [\n",
    "        '--limit_predict_batches', 10,\n",
    "    ]\n",
    "\n",
    "\n",
    "config = ScriptRunConfig(\n",
    "    source_directory = str(project_dir), \n",
    "    script = \"score.py\",\n",
    "    arguments=args,\n",
    ")\n",
    "run_config.target = compute_target\n",
    "config.run_config = run_config\n",
    "\n",
    "run = exp.submit(config)\n",
    "display(Markdown(f\"\"\"\n",
    "- Experiement: [{run.experiment.name}]({run.experiment.get_portal_url()})\n",
    "- Run: [{run.display_name}]({run.get_portal_url()})\n",
    "- Target: {config.run_config.target}\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Move to another notebook or delete?\n",
    "\n",
    "# experiment_name = \"dataset_debug\"\n",
    "# chex_dataset = Dataset.get_by_name(ws, name='chexpert')\n",
    "# pc_dataset = Dataset.get_by_name(ws, name=input_dataset_name)\n",
    "\n",
    "\n",
    "# exp = Experiment(workspace=ws, name=experiment_name)\n",
    "# environment_file = settings.CONDA_ENVIRONMENT_FILE\n",
    "# project_dir = Path(\"./experiment\")\n",
    "# pytorch_env = Environment.from_conda_specification(env_name, file_path =str(environment_file))\n",
    "\n",
    "# pytorch_env.register(workspace=ws)\n",
    "# build = pytorch_env.build(workspace=ws)\n",
    "\n",
    "# pytorch_env.environment_variables[\"RSLEX_DIRECT_VOLUME_MOUNT\"] = \"True\"\n",
    "\n",
    "# print(\"Experiment:\", exp.name)\n",
    "# print(\"Environment:\", pytorch_env.name)\n",
    "\n",
    "# run_config = RunConfiguration()\n",
    "# run_config.environment = pytorch_env\n",
    "# run_config.docker = DockerConfiguration(use_docker=True, shm_size=\"100G\")\n",
    "\n",
    "# args = [\n",
    "#     '--data1', pc_dataset.as_named_input('padchestv1').as_mount(),\n",
    "#     '--data2', chex_dataset.as_named_input('chexpertv1').as_mount(),\n",
    "#     ]\n",
    "\n",
    "\n",
    "# config = ScriptRunConfig(\n",
    "#     source_directory = str(project_dir), \n",
    "#     script = \"dataset_test.py\",\n",
    "#     arguments=args,\n",
    "# )\n",
    "\n",
    "# config.run_config = run_config\n",
    "\n",
    "# config.run_config.target = compute_target\n",
    "\n",
    "# # config.run_config.target = \"nc6-uswest2\"\n",
    "\n",
    "# run = exp.submit(config)\n",
    "# display(Markdown(f\"\"\"\n",
    "# - Experiement: [{run.experiment.name}]({run.experiment.get_portal_url()})\n",
    "# - Run: [{run.display_name}]({run.get_portal_url()})\n",
    "# - Target: {config.run_config.target}\n",
    "# \"\"\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40209cfd1e49aba1e20a3908f9a243f43b2ed73034fd3a81730d62124bbdcdae"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
