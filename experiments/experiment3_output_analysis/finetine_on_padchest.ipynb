{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (cloudpickle 2.0.0 (d:\\code\\mlopsday2\\medimaging-modeldriftmonitoring\\.venv\\lib\\site-packages), Requirement.parse('cloudpickle<2.0.0,>=1.1.0'), {'azureml-dataprep'}).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.35.0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import azureml\n",
    "from IPython.display import display, Markdown\n",
    "from azureml.core import Datastore, Experiment, ScriptRunConfig, Workspace, RunConfiguration\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "from azureml.exceptions import UserErrorException\n",
    "import shutil\n",
    "\n",
    "\n",
    "from model_drift import settings, helpers\n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    }
   ],
   "source": [
    "# Connect to workspace\n",
    "ws = Workspace.from_config(settings.AZUREML_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "- Environment: finetune-padchest\n",
       "- Experiment: [finetune-padchest](https://ml.azure.com/experiments/finetune-padchest?wsid=/subscriptions/9ca8df1a-bf40-49c6-a13f-66b72a85f43c/resourcegroups/MLOps-Prototype/workspaces/MLOps_shared&tid=72f988bf-86f1-41af-91ab-2d7cd011db47)\n",
       "- Run: [brave_evening_9xj1507l](https://ml.azure.com/runs/finetune-padchest_1635550789_eab7e5c7?wsid=/subscriptions/9ca8df1a-bf40-49c6-a13f-66b72a85f43c/resourcegroups/MLOps-Prototype/workspaces/MLOps_shared&tid=72f988bf-86f1-41af-91ab-2d7cd011db47)\n",
       "- Target: nc24-uswest2\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbg = False\n",
    "\n",
    "log_refresh_rate = 25\n",
    "if dbg:\n",
    "    log_refresh_rate = 1\n",
    "\n",
    "env_name = \"finetune-padchest\"\n",
    "\n",
    "# Name experiement\n",
    "experiment_name = 'finetune-padchest' if not dbg else 'finetune-padchest-dbg'\n",
    "\n",
    "# Input Dataset\n",
    "dataset = Dataset.get_by_name(ws, name='padchest')\n",
    "\n",
    "#Experiment\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "\n",
    "\n",
    "\n",
    "#Environment\n",
    "environment_file = settings.CONDA_ENVIRONMENT_FILE\n",
    "project_dir = settings.SRC_DIR\n",
    "pytorch_env = Environment.from_conda_specification(env_name, file_path =str(environment_file))\n",
    "pytorch_env.register(workspace=ws)\n",
    "build = pytorch_env.build(workspace=ws)\n",
    "pytorch_env.environment_variables[\"RSLEX_DIRECT_VOLUME_MOUNT\"] = \"True\"\n",
    "\n",
    "# Run Configuration\n",
    "run_config = RunConfiguration()\n",
    "run_config.environment_variables[\"RSLEX_DIRECT_VOLUME_MOUNT\"] = \"True\"\n",
    "run_config.environment = pytorch_env\n",
    "run_config.docker = DockerConfiguration(use_docker=True, shm_size=\"100G\")\n",
    "args = [\n",
    "    '--data_folder', dataset.as_named_input('dataset').as_mount(),\n",
    "    '--run_azure', 1,\n",
    "    \"--batch_size\", 6,\n",
    "    '--output_dir', './outputs',\n",
    "    \"--pretrained\", \"pretrained-chexpert/iter_662400.pth.tar\",\n",
    "\n",
    "    '--max_epochs', 24 if not dbg else 5,\n",
    "    '--num_workers', -1,\n",
    "\n",
    "    '--progress_bar_refresh_rate', log_refresh_rate,\n",
    "    \"--log_every_n_steps\", log_refresh_rate,\n",
    "    \"--flush_logs_every_n_steps\", log_refresh_rate,\n",
    "    \"--accelerator\", \"ddp\",\n",
    "    \"--freeze_backbone\", 0,\n",
    "    \"--frontal_only\", 1,\n",
    "\n",
    "    ]\n",
    "\n",
    "if dbg:\n",
    "    args += [\n",
    "        '--limit_train_batches', 5,\n",
    "        '--limit_val_batches', 40,\n",
    "        \"--num_sanity_val_steps\", 40\n",
    "    ]\n",
    "\n",
    "if \"--num_sanity_val_steps\" not in args:\n",
    "    args += [\"--num_sanity_val_steps\", 0]\n",
    "\n",
    "config = ScriptRunConfig(\n",
    "    source_directory = str(project_dir), \n",
    "    script = \"scripts/finetune/train.py\",\n",
    "    arguments=args,\n",
    ")\n",
    "\n",
    "config.run_config = run_config\n",
    "\n",
    "config.run_config.target = \"nc24-uswest2\"\n",
    "# config.run_config.target = \"NC24rs-v3-usw2-d\"\n",
    "run = exp.submit(config)\n",
    "display(Markdown(f\"\"\"\n",
    "- Environment: {pytorch_env.name}\n",
    "- Experiment: [{run.experiment.name}]({run.experiment.get_portal_url()})\n",
    "- Run: [{run.display_name}]({run.get_portal_url()})\n",
    "- Target: {config.run_config.target}\n",
    "\"\"\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dataset_len:\n",
    "#   test: 46917\n",
    "#   train: 91726\n",
    "#   val: 22176\n",
    "# split_dates:\n",
    "# - '2013-01-01'\n",
    "# - '2014-01-01'\n",
    "# test_kwargs:\n",
    "#   frontal_only: false\n",
    "# train_kwargs:\n",
    "#   frontal_only: 0\n",
    "# val_kwargs:\n",
    "#   frontal_only: false\n",
    "\n",
    "\n",
    "# dataset_len:\n",
    "#   test: 31644\n",
    "#   train: 63699\n",
    "#   val: 15267\n",
    "# split_dates:\n",
    "# - '2013-01-01'\n",
    "# - '2014-01-01'\n",
    "# test_kwargs:\n",
    "#   frontal_only: 1\n",
    "# train_kwargs:\n",
    "#   frontal_only: 1\n",
    "# val_kwargs:\n",
    "#   frontal_only: 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import GridParameterSampling, RandomParameterSampling, BanditPolicy, HyperDriveConfig, uniform, PrimaryMetricGoal, choice, loguniform\n",
    "run_config = RunConfiguration()\n",
    "\n",
    "cluster_name = \"NC24rs-v3-usw2-d\"\n",
    "# cluster_name = \"nc24-uswest2\"\n",
    "\n",
    "run_config.environment = pytorch_env\n",
    "run_config.docker = DockerConfiguration(use_docker=True, shm_size=\"100G\")\n",
    "run_config.target = cluster_name\n",
    "\n",
    "\n",
    "param_sampling = RandomParameterSampling(\n",
    "    {   \"freeze_backbone\": choice([0, 1]),\n",
    "        \"batch_size\": choice([8, 12, 16]),\n",
    "        \"learning_rate\": choice(1e-2, 1e-4, 1e-4),\n",
    "        \"step_size\": choice([4, 8, 12]),\n",
    "        \"accumulate_grad_batches\": choice([1, 2, 4]),\n",
    "        \"frontal_only\": choice([0, 1])\n",
    "    }\n",
    ")\n",
    "\n",
    "experiment_name = 'finetune-padchest-hyper'\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "config.run_config = run_config\n",
    "hyperdrive_config = HyperDriveConfig(run_config=config,\n",
    "                                     hyperparameter_sampling=param_sampling, \n",
    "                                     policy=None,\n",
    "                                     primary_metric_name='val/AUROC.mean',\n",
    "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                     max_total_runs=6*18,\n",
    "                                     max_concurrent_runs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "- Experiment: [finetune-padchest-hyper](https://ml.azure.com/experiments/finetune-padchest-hyper?wsid=/subscriptions/9ca8df1a-bf40-49c6-a13f-66b72a85f43c/resourcegroups/MLOps-Prototype/workspaces/MLOps_shared&tid=72f988bf-86f1-41af-91ab-2d7cd011db47)\n",
       "- Run: [quirky_chin_xwwgjcyl](https://ml.azure.com/runs/HD_3a28a4dc-e52d-4dab-b88c-b087a93e26eb?wsid=/subscriptions/9ca8df1a-bf40-49c6-a13f-66b72a85f43c/resourcegroups/MLOps-Prototype/workspaces/MLOps_shared&tid=72f988bf-86f1-41af-91ab-2d7cd011db47)\n",
       "- Target: NC24rs-v3-usw2-d\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start the HyperDrive run\n",
    "hyperdrive_run = exp.submit(hyperdrive_config)\n",
    "display(Markdown(f\"\"\"\n",
    "- Experiment: [{hyperdrive_run.experiment.name}]({hyperdrive_run.experiment.get_portal_url()})\n",
    "- Run: [{hyperdrive_run.display_name}]({hyperdrive_run.get_portal_url()})\n",
    "- Target: {config.run_config.target}\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40209cfd1e49aba1e20a3908f9a243f43b2ed73034fd3a81730d62124bbdcdae"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
