{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from model_drift import settings, helpers\n",
    "from model_drift.data.utils import nested2series\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from model_drift.drift.tabular import TabularDriftCalculator\n",
    "from model_drift.drift.numeric import KSDriftCalculator, BasicDriftCalculator\n",
    "from model_drift.drift.categorical import ChiSqDriftCalculator\n",
    "from model_drift.drift.collection import DriftCollectionCalculator\n",
    "from model_drift.drift.performance import AUROCCalculator\n",
    "\n",
    "from model_drift.drift.sampler import Sampler\n",
    "from model_drift.data.padchest import PadChest\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl_file = str(settings.TOP_DIR.joinpath(\"results\", 'vae', 'padchest-trained', \"all-data\", 'preds.jsonl'))\n",
    "vae_df = helpers.jsonl_files2dataframe(jsonl_file)\n",
    "vae_df = pd.concat(\n",
    "    [\n",
    "        vae_df,\n",
    "        pd.DataFrame(vae_df['mu'].values.tolist(), columns=[f\"mu.{c}\" for c in range(128)])\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "vae_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_drift.data.padchest import LABEL_MAP\n",
    "label_cols = list(LABEL_MAP)\n",
    "jsonl_file = str(settings.TOP_DIR.joinpath(\"results\", 'classifier', 'padchest-trained', \"frontal_only\", \"preds.jsonl\"))\n",
    "scores_df = helpers.jsonl_files2dataframe(jsonl_file)\n",
    "scores_df = pd.concat(\n",
    "    [\n",
    "        scores_df,\n",
    "        pd.DataFrame(scores_df['activation'].values.tolist(), columns=[f\"activation.{c}\" for c in label_cols])\n",
    "    ],\n",
    "    axis=1)\n",
    "scores_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_drift.data.utils import fix_strlst, remap_labels\n",
    "# Load padchest CSV\n",
    "pc = PadChest(settings.PADCHEST_FILENAME, label_map=LABEL_MAP)\n",
    "\n",
    "df_o = pc.df[['ImageID','Labels']].copy().rename(columns={'Labels': 'OriginalLabels'})\n",
    "df_o['OriginalLabels'] = fix_strlst(df_o['OriginalLabels'])\n",
    "pc.prepare()\n",
    "\n",
    "print(pc.df.query(\"Frontal\")['Labels'].apply(len).describe())\n",
    "\n",
    "pc.merge(vae_df, left_on=\"ImageID\", right_on=\"index\", how='inner')\n",
    "pc.merge(scores_df, left_on=\"ImageID\", right_on=\"index\", how='inner')\n",
    "pc.merge(df_o, left_on=\"ImageID\", right_on=\"ImageID\", how='inner')\n",
    "\n",
    "\n",
    "# train, val, test = pc.split(settings.PADCHEST_SPLIT_DATES, studydate_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat(\n",
    "#     {\n",
    "#         \"all\": pc.df[\"StudyDate\"].describe(datetime_is_numeric=True),\n",
    "#         \"train\": train.df[\"StudyDate\"].describe(datetime_is_numeric=True),\n",
    "#         \"val\": val.df[\"StudyDate\"].describe(datetime_is_numeric=True),\n",
    "#         \"test\": test.df[\"StudyDate\"].describe(datetime_is_numeric=True),\n",
    "#     },\n",
    "#     axis=1,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sample_bad = pc.df.set_index(\"StudyDate\").loc[\"2016-12-01\":\"2016-12-28\"].query(\"Frontal\")\n",
    "sample_good = pc.df.set_index(\"StudyDate\").loc[\"2015-12-01\":\"2015-12-28\"].query(\"Frontal\")\n",
    "\n",
    "len(sample_bad), len(sample_good)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_drift.data.utils import fix_strlst, remap_labels, remap_label_list\n",
    "\n",
    "remap_labels(sample_bad['OriginalLabels'], label_map=LABEL_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = list(pc.label_map)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_bad['activation'].apply(np.mean).mean(), sample_good['activation'].apply(np.mean).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.df['Labels'].apply(len).max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "functools.reduce(lambda x1, x2: set(x1).union(x2), sample_bad['Labels'])\n",
    "functools.reduce(lambda x1, x2: set(x1).union(x2), sample_good['Labels'])\n",
    "\n",
    "\n",
    "x1 = sample_bad['Labels'].apply(Counter).sum()\n",
    "\n",
    "x2 = sample_good['Labels'].apply(Counter).sum()\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "x1.most_common()[:10], x2.most_common()[:10]\n",
    "\n",
    "                 \n",
    "                #  , sample_good['Labels'].apply(len).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "s = sample_bad\n",
    "th = 0.5\n",
    "\n",
    "def class_report(s, th=0.5, drop_zero=False):\n",
    "    scores = np.vstack(s['activation'].values)\n",
    "    labels = np.vstack(s['label'].values).astype(int)\n",
    "    target_names = np.array(list(LABEL_MAP))\n",
    "    \n",
    "\n",
    "    keeps = (labels.sum(axis=0) > 0)\n",
    "    output = metrics.classification_report(labels, scores>=th, target_names=target_names, output_dict=True)\n",
    "    graphs = defaultdict(dict)\n",
    "    for i, k in enumerate(target_names):\n",
    "        if keeps[i] == 0: continue\n",
    "        output[k]['auroc'] = metrics.roc_auc_score(\n",
    "            labels[:, i], scores[:, i])\n",
    "        # graphs[k]['fpr'], graphs[k]['tpr'], graphs[k]['thrs'] = metrics.roc_curve(labels[:, i], scores[:, i])\n",
    "    \n",
    "        \n",
    "    \n",
    "        \n",
    "    output['macro avg']['auroc'] = (metrics.roc_auc_score(labels[:, keeps], scores[:, keeps], labels=target_names[keeps], average='macro'))\n",
    "    output['micro avg']['auroc'] = (metrics.roc_auc_score(labels, scores, average='micro'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # print(output)\n",
    "    return pd.DataFrame(output), graphs\n",
    "\n",
    "\n",
    "o1, graphs_bad = class_report(sample_bad, drop_zero=True)\n",
    "o2, graphs_good = class_report(sample_good, drop_zero=True)\n",
    "\n",
    "\n",
    "pd.concat({\"bad\":o1, \"good\":o2}).T.swaplevel(0,1,axis=1).sort_index(axis=1)['auroc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FLOAT(x): return pd.to_numeric(x, errors='coerce').astype(float)\n",
    "def CAT(x): return x.astype('category')\n",
    "\n",
    "\n",
    "vae_cols = {c: FLOAT for c in list(pc.df) if c.startswith(\"mu.\") and 'all' not in c}\n",
    "score_cols = {c: FLOAT for c in list(pc.df) if c.startswith(\"activation.\") and 'all' not in c}\n",
    "metadata_cols = {\n",
    "    'age': FLOAT,\n",
    "    'Projection': CAT,\n",
    "    \"PatientSex_DICOM\": CAT,\n",
    "    \"ViewPosition_DICOM\": CAT,\n",
    "    \"Modality_DICOM\": CAT,\n",
    "    \"Manufacturer_DICOM\": CAT,\n",
    "    \"PhotometricInterpretation_DICOM\": CAT,\n",
    "    \"PixelRepresentation_DICOM\": CAT,\n",
    "    \"PixelAspectRatio_DICOM\": CAT,\n",
    "    \"SpatialResolution_DICOM\": FLOAT,\n",
    "    \"BitsStored_DICOM\": CAT,\n",
    "    \"WindowCenter_DICOM\": FLOAT,\n",
    "    \"WindowWidth_DICOM\": FLOAT,\n",
    "    \"Rows_DICOM\": FLOAT,\n",
    "    \"Columns_DICOM\": FLOAT,\n",
    "    \"XRayTubeCurrent_DICOM\": CAT,\n",
    "    \"Exposure_DICOM\": FLOAT,\n",
    "    \"ExposureInuAs_DICOM\": FLOAT,\n",
    "    \"RelativeXRayExposure_DICOM\": FLOAT,\n",
    "    \"Frontal\": lambda x: x.astype(str),\n",
    "}\n",
    "\n",
    "\n",
    "for c, f in metadata_cols.items():\n",
    "    pc.df[c] = f(pc.df[c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "\n",
    "def make_plotly_graph(graphs):\n",
    "    fig = make_subplots(1, 1, vertical_spacing=0.05, horizontal_spacing=0.05)\n",
    "    for k, g in graphs.items():\n",
    "        x = g['fpr']\n",
    "        y = g['tpr']\n",
    "        fig.add_trace(go.Line(x=x, y=y, showlegend=True, name=k))\n",
    "\n",
    "\n",
    "    # fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "    fig.update_yaxes(range=[0, 1.01], constrain=\"domain\")\n",
    "    fig.update_xaxes(range=[0, 1.01], constrain=\"domain\")\n",
    "    fig.update_layout(height=400, width=600, margin=go.layout.Margin(\n",
    "        l=10,  # left margin\n",
    "        r=10,  # right margin\n",
    "        b=20,  # bottom margin\n",
    "        t=20,  # top margin\n",
    "    ))\n",
    "    return fig\n",
    "\n",
    "sample = sample_bad\n",
    "def make_hist_plot(sample):\n",
    "    fig = make_subplots(5, 4, vertical_spacing=.15)\n",
    "    for i, col in enumerate(metadata_cols):\n",
    "        c = i%4+1\n",
    "        r = i//4+1\n",
    "        try:\n",
    "            hist = pd.cut(sample[col], bins=25).value_counts().sort_index()\n",
    "        except:\n",
    "            hist = sample[col].value_counts().sort_index()\n",
    "        fig.add_trace(go.Bar(x=hist.index.map(str), y=hist, name=col), row=r, col=c)\n",
    "        fig.update_layout(height=900,\n",
    "                        margin=go.layout.Margin(\n",
    "                            l=10,  # left margin\n",
    "                            r=10,  # right margin\n",
    "                            b=20,  # bottom margin\n",
    "                            t=20,  # top margin\n",
    "                        ))\n",
    "    return fig\n",
    "\n",
    "\n",
    "fig = make_hist_plot(sample)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html, display_markdown, HTML, Markdown, display\n",
    "import os\n",
    "import json\n",
    "output_dir = settings.TOP_DIR.joinpath(\"html\")\n",
    "if not os.path.exists(output_dir):\n",
    "  os.makedirs(output_dir)\n",
    "\n",
    "sample_bad = pc.df.set_index(\"StudyDate\").loc[\"2016-12-01\":\"2016-12-28\"].query(\"Frontal == 'True'\")\n",
    "sample_good = pc.df.set_index(\"StudyDate\").loc[\"2015-12-01\":\"2015-12-28\"].query(\"Frontal == 'True'\")\n",
    "\n",
    "sample = sample_bad\n",
    "name = \"dip in late 2016\"\n",
    "fname = \"auroc_dip_images\"\n",
    "\n",
    "sample = sample_good\n",
    "name = \"normal performance\"\n",
    "fname = \"auroc_normal_images\"\n",
    "\n",
    "N = 8\n",
    "o1, graphs = class_report(sample)\n",
    "fig = make_plotly_graph(graphs)\n",
    "fig2 = make_hist_plot(sample)\n",
    "o1 = o1.T.join(sample[list(pc.label_map)].agg([\"sum\", \"count\", \"mean\"]).T).apply(lambda x: np.round(x, 3)).fillna(' - ')\n",
    "\n",
    "\n",
    "sas = \"sv=2020-08-04&st=2021-11-23T18%3A15%3A07Z&se=2021-12-24T18%3A15%3A00Z&sr=c&sp=rl&sig=Zxi28kTgEj%2FIlv1RvTiuP%2FMGoc4DdoMtacHXxCc1VpA%3D\"\n",
    "container_url = \"https://mlopsday2datasets.blob.core.windows.net/padchest/png/\"\n",
    "\n",
    "\n",
    "#<link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.0.0-alpha.4/css/bootstrap.min.css\">\n",
    "html = \"\"\"\n",
    "<style>\n",
    ".container {\n",
    "    width: 80%;\n",
    "    margin: 0 auto;\n",
    "  }\n",
    "\n",
    ".gallery {\n",
    "    display: block; \n",
    "    line-height:0;\n",
    "   -webkit-column-count:5; /* split it into 5 columns */\n",
    "   -webkit-column-gap:5px; /* give it a 5px gap between columns */\n",
    "   -moz-column-count:5;\n",
    "   -moz-column-gap:5px;\n",
    "   column-count:4;\n",
    "   column-gap:5px;\n",
    "}\n",
    "\n",
    ".gallery img {\n",
    "   width: 100% !important;\n",
    "   height: auto !important;\n",
    "   margin-bottom:5px; /* to match column gap */\n",
    "}\n",
    "    </style>\n",
    "    \n",
    "    \n",
    "<div class=\"container\">\n",
    "\"\"\"\n",
    "\n",
    "html += f\"\"\"<div class=\"row\"><h1>{name}, Between {sample.index.min()} to {sample.index.max()} </h1></div>\n",
    "\"\"\"\n",
    "\n",
    "html += \"\"\"<div class=\"row\">\"\"\" + o1.to_html() + \"\"\"</div>\"\"\"\n",
    "html += \"\"\"<div class=\"row\">\"\"\" + fig.to_html() + \"\"\"</div>\"\"\"\n",
    "html += \"\"\"<div class=\"row\">\"\"\" + fig2.to_html() + \"\"\"</div>\"\"\"\n",
    "\n",
    "for c in label_cols:\n",
    "  s = sample[sample[c]>0]\n",
    "  Ns = min(N, len(s))\n",
    "  html += f\"\"\"<h2>{c} ({Ns} of {len(s)})<h2><div class=\"row gallery\">\n",
    "\"\"\"\n",
    "\n",
    "  for i, (ix, row) in enumerate(s.sample(Ns).sort_index().iterrows()):\n",
    "    tooltip = {k:str(v) for k,v in row.to_dict().items()}\n",
    "    tooltip =  json.dumps(tooltip, indent=2).replace('\"', '').strip(\"{\").strip()\n",
    "    html += \"\"\"\n",
    "      <img data=\"{ImageDir}/{ImageID}\" \n",
    "      class=\"padchest\" id=\"{i}\" >\n",
    "    \"\"\".format(\n",
    "        i=i, **row, tooltip=tooltip)\n",
    "  html += f\"\"\"</div> <!-- row -->\"\"\"\n",
    "  \n",
    "\n",
    "html += f\"\"\"\n",
    "</div> <!-- container -->\n",
    "<script>\n",
    "const url = \"{container_url}\"; \n",
    "const sas = \"{sas}\"; \n",
    "var x = document.getElementsByClassName(\"padchest\");\n",
    "var i;\n",
    "for (i = 0; i < x.length; i++) {{\n",
    "  let data = x[i].getAttribute(\"data\");\n",
    "  x[i].src = url + data + \"?\" + sas\n",
    "}}\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "print(fname)\n",
    "with open(f\"{str(output_dir)}/{fname}.html\", 'w') as f:\n",
    "  print(html, file=f)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOAT = KSDriftCalculator\n",
    "CAT = ChiSqDriftCalculator\n",
    "\n",
    "cols = {\n",
    "    'age': FLOAT,\n",
    "    'Projection': CAT,\n",
    "    \"PatientSex_DICOM\": CAT,\n",
    "    \"ViewPosition_DICOM\": CAT,\n",
    "    \"Modality_DICOM\": CAT,\n",
    "    \"Manufacturer_DICOM\": CAT,\n",
    "    \"PhotometricInterpretation_DICOM\": CAT,\n",
    "    \"PixelRepresentation_DICOM\": CAT,\n",
    "    \"PixelAspectRatio_DICOM\": CAT,\n",
    "    \"SpatialResolution_DICOM\": CAT,\n",
    "    \"BitsStored_DICOM\": CAT,\n",
    "    \"WindowCenter_DICOM\": FLOAT,\n",
    "    \"WindowWidth_DICOM\": FLOAT,\n",
    "    \"Rows_DICOM\": FLOAT,\n",
    "    \"Columns_DICOM\": FLOAT,\n",
    "    \"XRayTubeCurrent_DICOM\": CAT,\n",
    "    \"Exposure_DICOM\": CAT,\n",
    "    \"ExposureInuAs_DICOM\": FLOAT,\n",
    "    \"RelativeXRayExposure_DICOM\": FLOAT,\n",
    "    'Frontal': BasicDriftCalculator,\n",
    "}\n",
    "\n",
    "cols.update({c:FLOAT for c in list(pc.df) if c.startswith(\"mu.\") and 'all' not in c})\n",
    "cols.update({c:FLOAT for c in list(pc.df) if c.startswith(\"activation.\") and 'all' not in c})\n",
    "cols[(\"score\", \"label\")] = AUROCCalculator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = \"30D\"\n",
    "stride = \"D\"\n",
    "ref_frontal_only = True\n",
    "min_periods = 150\n",
    "\n",
    "nonfrontal_add_date = \"2007-05-01\"\n",
    "frontal_remove_date = None\n",
    "\n",
    "replacement = True\n",
    "sample_size = 2000\n",
    "n_samples = 20\n",
    "\n",
    "\n",
    "sampler = Sampler(sample_size, replacement=replacement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refdf = val.df.copy()\n",
    "if ref_frontal_only:\n",
    "    refdf = refdf.query(\"Frontal\")\n",
    "\n",
    "\n",
    "print(len(refdf), len(val.df))\n",
    "\n",
    "dwc = TabularDriftCalculator(refdf)\n",
    "\n",
    "for c, kls in cols.items():\n",
    "    dwc.add_drift_stat(c, kls)\n",
    "dwc.prepare()\n",
    "\n",
    "target_df = pc.df.set_index('StudyDate')\n",
    "\n",
    "\n",
    "nonfrontals_target_df = target_df.query(\"~Frontal\").copy()\n",
    "frontals_target_df = target_df.query(\"Frontal\").copy()\n",
    "\n",
    "# print(\"nonfrontals_target_df\", nonfrontals_target_df.index.min(), nonfrontals_target_df.index.max())\n",
    "# print(\"frontals_target_df\", frontals_target_df.index.min(), frontals_target_df.index.max())\n",
    "\n",
    "nonfrontals_target_df = nonfrontals_target_df.loc[nonfrontal_add_date:]\n",
    "frontals_target_df = frontals_target_df.loc[:frontal_remove_date]\n",
    "\n",
    "print(\"nonfrontals_target_df\", nonfrontals_target_df.index.min(), nonfrontals_target_df.index.max())\n",
    "print(\"frontals_target_df\", frontals_target_df.index.min(), frontals_target_df.index.max())\n",
    "\n",
    "print(target_df['Frontal'].mean())\n",
    "target_df = pd.concat([nonfrontals_target_df, frontals_target_df ]).sort_index()\n",
    "print(target_df['Frontal'].mean())\n",
    "\n",
    "print(len(target_df), len(pc.df.set_index('StudyDate')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = settings.TOP_DIR.joinpath(\n",
    "    \"results\", \"drift_csvs\", f\"combined-od-inject-addnfrnt{nonfrontal_add_date}-rmfrnt{frontal_remove_date}_s{stride}-w{window}-min{min_periods}_frontalonly-ref{ref_frontal_only}_Samp-ss{sample_size}-n{n_samples}-repl{replacement}.csv\")\n",
    "print(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_drift.data.utils import rolling_window_dt_apply\n",
    "\n",
    "frontal_over_time = rolling_window_dt_apply(pc.df.set_index(\"StudyDate\"), lambda x: {'frontal': x['Frontal'].mean()}, n_jobs=5, backend='threading')\n",
    "\n",
    "frontal_over_time.plot(y='frontal', figsize=(20, 8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = dwc.rolling_window_predict(target_df,\n",
    "                                    sampler=sampler, n_samples=n_samples,\n",
    "                                    stride=stride, window=window, min_periods=min_periods,\n",
    "                                    n_jobs=8, backend=\"threading\"\n",
    "                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fname)\n",
    "output.to_csv(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "output['score'].ewm(span=90).mean().plot(figsize=(20, 8))\n",
    "\n",
    "frontal_over_time.ewm(span=90).mean().plot(y='frontal', figsize=(20, 8))\n",
    "\n",
    "frontal_over_time.ewm(span=90).mean().plot(y='window_count', figsize=(20, 8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[[\"Frontal\", 'score']].drop([(\"Frontal\", 'stats', \"std\")], axis=1).plot(figsize=(20, 8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40209cfd1e49aba1e20a3908f9a243f43b2ed73034fd3a81730d62124bbdcdae"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
