{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, HTML\n",
    "import plotly.express as px\n",
    "import itertools\n",
    "\n",
    "from azureml.core import Run, Model\n",
    "from azureml.core import Datastore, Experiment, ScriptRunConfig, Workspace\n",
    "\n",
    "from model_drift import settings\n",
    "from model_drift.helpers import column_xs, correlate_performance, mutual_info_performance, w_avg\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config(settings.AZUREML_CONFIG)\n",
    "\n",
    "experiment_name = 'generate-drift-csv-3'\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = []\n",
    "for run in exp.get_runs():\n",
    "    if run.status != \"Completed\":\n",
    "        continue\n",
    "    d = dict(**run.tags)\n",
    "    d['id'] = run.id\n",
    "    d['display_name'] = run.display_name\n",
    "    d['url'] = run.get_portal_url()\n",
    "    d['run'] = run\n",
    "    df.append(d)\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame(df).set_index(['display_name'])\n",
    "df = df.sort_values([\"window\", \"nonfrontal_add_date\", \"frontal_remove_date\", \"peds_weight\"])\n",
    "df = df[~df['frontal_remove_date'].str.contains('2013').astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# r.get_details()[\"endTimeUtc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_arg_col(c):\n",
    "    if \"mlflow\" in c or \"_aml\" in c or 'run_' in c or 'url' in c:\n",
    "        return False\n",
    "\n",
    "    ignore = [\"output_dir\", \"input_dir\", 'run', 'display_name', 'id']\n",
    "\n",
    "    return c not in ignore\n",
    "arg_cols = [c for c in df.columns if is_arg_col(c)]\n",
    "\n",
    "arg_df = df[arg_cols].query(\"classifier_dataset == 'padchest-finetuned-chx-frontalonly'\").copy()\n",
    "arg_df = arg_df[~arg_df.duplicated(keep='last')]\n",
    "arg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_links_script = \"\"\"\n",
    "              <script>\n",
    "                var x = document.getElementsByTagName('a');\n",
    "                var i;\n",
    "                for (i = 0; i < x.length; i++) {{\n",
    "                    let url = x[i].getAttribute(\"href\");\n",
    "                    x[i].href = url + window.location.search;\n",
    "                }}\n",
    "                </script>\n",
    "              \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_top_dir = settings.TOP_DIR.joinpath(\"html\", \"graphs_paper\")\n",
    "html_top_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arg_df2 =arg_df[[c for c in arg_df if arg_df[c].fillna('NA').nunique() > 1]]\n",
    "arg_df2['Link'] = [f\"\"\"<a href=\"{name}/index.html\" disabled=>Graphs</a>\"\"\" if html_top_dir.joinpath(name).exists() else \"N/A\" for name in arg_df2.index]\n",
    "\n",
    "# with open(html_top_dir.joinpath(\"index.html\"), 'w') as f:\n",
    "#         print(\"\"\"\n",
    "#             <style>\n",
    "#             table {\n",
    "#             font-family: arial, sans-serif;\n",
    "#             border-collapse: collapse;\n",
    "#             width: 80%;\n",
    "#             }\n",
    "\n",
    "#             td, th {\n",
    "#             border: 1px solid #dddddd;\n",
    "#             text-align: left;\n",
    "#             padding: 8px;\n",
    "#             }\n",
    "\n",
    "#             tr:nth-child(even) {\n",
    "#             background-color: #dddddd;\n",
    "#             }\n",
    "#             </style>\n",
    "#             pre<br />\n",
    "#         \"\"\", file=f)\n",
    "#         print(f\"Generated: {datetime.datetime.now()}\", file=f)\n",
    "#         print(arg_df2.to_html(escape=False), file=f)\n",
    "#         print(fix_links_script, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.loc[arg_df.index]\n",
    "\n",
    "arg_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_row = df.loc[[not html_top_dir.joinpath(name).exists() for name in df.index]].iloc[0]\n",
    "run_name, verbose_name = \"tender_pear_lfbd6wwg\", \"baseline\"\n",
    "run_name, verbose_name = \"tender_pear_lfbd6wwg\", \"baseline_2row\"\n",
    "# run_name, verbose_name = \"orange_scooter_dry7q6y9\", \"inject-laterals\"\n",
    "\n",
    "\n",
    "run_row = df.loc[run_name]\n",
    "\n",
    "r = run_row['run']\n",
    "name = run_row.name\n",
    "\n",
    "\n",
    "\n",
    "# Diplay settings\n",
    "span = 7\n",
    "which = 'mean'\n",
    "clip = 10\n",
    "if float(run_row['peds_weight']):\n",
    "    performance_col = (\"performance\", \"Pneumonia\", \"auroc\")\n",
    "else:\n",
    "    performance_col = (\"performance\", \"macro avg\", \"auroc\")\n",
    "\n",
    "congruency_measure_col = ('in_distro', 'stats', 'mean')\n",
    "add_error_bars = True\n",
    "\n",
    "standardize_dates = (settings.PADCHEST_SPLIT_DATES[0], settings.PADCHEST_SPLIT_DATES[1])\n",
    "standardize_ix = pd.date_range(*standardize_dates)\n",
    "stat = []\n",
    "stat.append('pval')\n",
    "stat.append('distance')\n",
    "\n",
    "verbose_name = verbose_name + '_' + '+'.join(stat) \n",
    "\n",
    "write_html = True\n",
    "graph_start = \"2014-01-01\"\n",
    "graph_end = \"2014-12-31\"\n",
    "\n",
    "\n",
    "font=dict(size=12)\n",
    "\n",
    "print(name, verbose_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from matplotlib import colors as mpl_colors\n",
    "from collections import defaultdict\n",
    "\n",
    "def to_rgba(rgb, alpha=None):\n",
    "    rgb = mpl_colors.to_rgb(rgb)\n",
    "    if alpha is None:\n",
    "        return \"rgb(%s, %s, %s)\" % (rgb[0], rgb[1], rgb[2])\n",
    "    return \"rgba(%s, %s, %s, %s)\" % (rgb[0], rgb[1], rgb[2], alpha)\n",
    "\n",
    "def line_maker(color, **l):\n",
    "    return dict(color=color, **l)\n",
    "\n",
    "def marker_maker(color, **l):\n",
    "    return dict(color=color)\n",
    "\n",
    "def smooth(y: pd.DataFrame):\n",
    "    if span > 0:\n",
    "        ys = y.ewm(span=span, ignore_na=False).mean()\n",
    "        ys[y.isna()] = None\n",
    "    else:\n",
    "        ys = y    \n",
    "    return ys\n",
    "\n",
    "def add_date_line(fig, date, name, y=1.08):\n",
    "    fig.add_shape(type='line',\n",
    "                x0=date,\n",
    "                y0=0,\n",
    "                x1=date,\n",
    "                y1=1,\n",
    "                line=dict(color='black', dash='dot'),\n",
    "                xref='x',\n",
    "                yref='paper'\n",
    "                )\n",
    "    fig.add_annotation(textangle=0,\n",
    "                    xref=\"x\",\n",
    "                    yref=\"paper\", x=date, y=y,\n",
    "                       text=name, showarrow=False,\n",
    "                       font=dict(size=18))\n",
    "\n",
    "def add_dates(fig, dates, line_y=1.05, include_date=True):\n",
    "    for name, date in dates.items():\n",
    "        if not pd.isna(date):\n",
    "            n = f\"{name}<br />({date})\" if include_date else name\n",
    "            add_date_line(fig, date, n, y=line_y)\n",
    "            \n",
    "def collect_corr(y, yp, name, when, weights_name, start_date=None, end_date=None):\n",
    "    yp = yp.loc[start_date: end_date]\n",
    "    y = y.loc[start_date: end_date]\n",
    "    c, cm = yp.corr(y), smooth(yp).corr(smooth(y))\n",
    "    return {\"name\": name, \"weights_name\": weights_name,\n",
    "                \"corr (raw)\": c, \"corr (smoothed)\": cm, \"when\": when}\n",
    "\n",
    "class FigureHelper(object):\n",
    "    \n",
    "    def __init__(self, x=None, color_list=px.colors.qualitative.Plotly, dashes=('solid',), smooth_func=smooth, merge_hover=True):\n",
    "        self.traces = []\n",
    "        self.error_traces = []\n",
    "        self.color_list = color_list\n",
    "        self.line_picker = itertools.cycle(itertools.product(dashes, self.color_list))\n",
    "        self.lines = defaultdict(lambda: dict(zip(['dash', 'color'], next(self.line_picker))))\n",
    "        self.names = set()\n",
    "        self.smooth = smooth_func\n",
    "        self.x = x\n",
    "        self.merge_hover = merge_hover\n",
    "        \n",
    "    def set_line(self, key, line=None):\n",
    "        line = line or {}\n",
    "        self.lines[key] = self.lines[key]\n",
    "        self.lines[key].update(line)\n",
    "        self.lines[key]['color'] = self.lines[key]['color']\n",
    "        return self.lines[key]\n",
    "        \n",
    "        \n",
    "    def make_error_traces(self, x, yu, yl, name, color, alpha):\n",
    "        \n",
    "        \n",
    "        # need to remove nans from error traces\n",
    "        k = ~(yu.isnull()|yl.isnull())\n",
    "        xe = x[k]\n",
    "        yl = yl[k]\n",
    "        yu = yu[k]\n",
    "        \n",
    "        return [go.Scatter(x=xe, \n",
    "                            y=yu, \n",
    "                            hoverinfo=\"skip\",\n",
    "                            showlegend=False,\n",
    "                            legendgroup=name,\n",
    "                            name=name,\n",
    "                            connectgaps=False,\n",
    "                            line=dict(width=0),\n",
    "                ), \n",
    "                go.Scatter(x=xe, \n",
    "                            y=yl,\n",
    "                            fillcolor=to_rgba(color, alpha),\n",
    "                            fill='tonexty',\n",
    "                            hoverinfo=\"skip\",\n",
    "                            showlegend=False,                            \n",
    "                            legendgroup=name,\n",
    "                            name=name,\n",
    "                            connectgaps=False,\n",
    "                            line=dict(width=0),\n",
    "                )]\n",
    "\n",
    "    def add_trace(self, y, name, x=None, kind=go.Scatter, color_key=None, row=1, col=1, line=None,\n",
    "                  std=None, yu=None, yl=None, **trace_kwargs):\n",
    "        color_key = color_key or name\n",
    "        trace_kwargs.setdefault('showlegend', name not in self.names)\n",
    "        self.names.add(name)\n",
    "        trace_kwargs.setdefault('legendgroup', name)\n",
    "        \n",
    "        line = self.set_line(color_key, line)\n",
    "        x = x or self.x\n",
    "        y = y.reindex(x)\n",
    "        t = kind(x=x, y=y, name=name, **trace_kwargs)\n",
    "        if not isinstance(t, go.Bar):\n",
    "            t.line = line_maker(**line)\n",
    "        else:\n",
    "            t.marker = marker_maker(**line)\n",
    "            \n",
    "    \n",
    "        self.traces.append((row, col, t))\n",
    "        \n",
    "        if std is not None:\n",
    "            yu = y+std\n",
    "            yl = y-std\n",
    "            \n",
    "        if yu is not None and yl is not None:\n",
    "            for t_ in self.make_error_traces(x, yu, yl, name=name, color=line[\"color\"], alpha=0.2):\n",
    "                self.error_traces.append((row, col, t_))\n",
    "    \n",
    "    \n",
    "    def add_bar(self, y, name, x=None, color_key=None, row=1, col=1, line=None, include_line=True,\n",
    "                **trace_kwargs):\n",
    "        \n",
    "        if include_line:\n",
    "            self.add_trace(y=y, name=name, color_key=color_key, line=line, row=row, col=col, **trace_kwargs)\n",
    "        self.add_trace(y=y, name=name, color_key=color_key, kind=go.Bar, line=line, row=row, col=col, **trace_kwargs)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def make_fig(self, **fig_kwargs):\n",
    "\n",
    "        data = {}\n",
    "        max_row = 1\n",
    "        max_col = 1\n",
    "        for r, c, t in self.traces:\n",
    "            max_row = max(r, max_row)\n",
    "            max_col = max(c, max_col)\n",
    "            data[t.name] = pd.Series(t.y, index=t.x)\n",
    "            \n",
    "        customdata = pd.DataFrame(data)\n",
    "        fig = make_subplots(rows=max_row, cols=max_col, **fig_kwargs)\n",
    "        for r, c, t in self.traces:\n",
    "            if self.merge_hover:\n",
    "                cus_cols = sorted(customdata)\n",
    "                ho = \"<br />\".join([\"{name}=%{{customdata[{i}]:.3f}}\".format(i=i, name=name) for i,name in enumerate(cus_cols)])\n",
    "                hovertemplate = \"%{x}<br>\" + f\"{t.name}: \" +\"%{y}<br><br>\"+f\"{ho}<extra></extra>\"\n",
    "                t.customdata = customdata[cus_cols]\n",
    "                t.hovertemplate = hovertemplate\n",
    "            # t.hoverlabel = {'bgcolor': 'white'}\n",
    "            fig.add_trace(t, row=r, col=c)\n",
    "                        \n",
    "        for r, c, t in self.error_traces:\n",
    "            fig.add_trace(t, row=r, col=c)\n",
    "        return fig\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_arg_col(c):\n",
    "    if \"mlflow\" in c or \"_aml\" in c or 'run_' in c or 'url' in c:\n",
    "        return False\n",
    "\n",
    "    ignore = [\"output_dir\", \"input_dir\", 'run', 'display_name', 'id']\n",
    "\n",
    "    return c not in ignore\n",
    "arg_cols = [c for c in df.columns if is_arg_col(c)]\n",
    "arg_row = run_row[arg_cols].copy()\n",
    "\n",
    "arg_row\n",
    "output_file_path = settings.TOP_DIR.joinpath('results', 'drift', name+\".csv\")\n",
    "fname = str(output_file_path)\n",
    "r.download_file(\"outputs/output.csv\", output_file_path=output_file_path)\n",
    "# # Settings to file CSV file\n",
    "\n",
    "display_args = [\"span\", \"which\", \"clip\", \"standardize_perf\", \"shift_drift_to_perf\", \"performance_col\", \"this_center\", \"this_range\", \"standardize_dates\", \"stat\", \"add_error_bars\"]\n",
    "d = locals()\n",
    "display_args = {k: d[k] for k in display_args if k in d}\n",
    "\n",
    "print(display_args)\n",
    "\n",
    "\n",
    "if not os.path.exists(fname):\n",
    "    raise ValueError(\"no fn\")\n",
    "\n",
    "combined_df_o = pd.read_csv(str(fname), index_col=0, header=[0, 1, 2, 3])\n",
    "combined_df_o.index = pd.to_datetime(combined_df_o.index)\n",
    "\n",
    "flip = column_xs(combined_df_o, include=[\"pval\"])\n",
    "combined_df_o[flip] = 1-combined_df_o[flip]\n",
    "combined_df = combined_df_o.copy()\n",
    "\n",
    "\n",
    "smooth_name = f\"ewm{span}\"\n",
    "\n",
    "error_df = combined_df.swaplevel(0, -1, axis=1)[[\"std\"]].swaplevel(0, -1, axis=1).droplevel(-1, axis=1).copy()\n",
    "combined_df = combined_df.swaplevel(0, -1, axis=1)[[which]].swaplevel(0, -1, axis=1).droplevel(-1, axis=1).copy()\n",
    "\n",
    "html_dir = html_top_dir.joinpath(name)\n",
    "perf_col_name = '-'.join(performance_col)\n",
    "\n",
    "if not os.path.exists(html_dir):\n",
    "    os.makedirs(html_dir)\n",
    "\n",
    "stat_str = '+'.join(stat)\n",
    "fn = f\"{html_dir}/{which}_{stat_str}_stdclip{clip}_smooth-{smooth_name}_{perf_col_name}.html\"\n",
    "\n",
    "print(\"output:\", fn)\n",
    "def is_arg_col(c):\n",
    "    if \"mlflow\" in c or \"_aml\" in c or 'run_' in c or 'url' in c:\n",
    "        return False\n",
    "\n",
    "    ignore = [\"output_dir\", \"input_dir\", 'run', 'display_name', 'id']\n",
    "    return c not in ignore\n",
    "\n",
    "arg_row = run_row[arg_cols].copy()\n",
    "display_row = pd.Series(display_args)\n",
    "params = pd.concat({'Drift': arg_row, \"Display\": display_row}, axis=0).rename(\"Value\").to_frame()\n",
    "\n",
    "if write_html:\n",
    "    with open(fn, 'w') as f:\n",
    "        print(\"\"\"\n",
    "            <style>\n",
    "            table {\n",
    "            font-family: arial, sans-serif;\n",
    "            border-collapse: collapse;\n",
    "            width: 80%;\n",
    "            }\n",
    "\n",
    "            td, th {\n",
    "            border: 1px solid #dddddd;\n",
    "            text-align: left;\n",
    "            padding: 8px;\n",
    "            }\n",
    "\n",
    "            tr:nth-child(even) {\n",
    "            background-color: #dddddd;\n",
    "            }\n",
    "            </style>\n",
    "        \"\"\", file=f)\n",
    "        print(f\"\"\"\n",
    "            <h1>Drift report</h1> created: {datetime.datetime.now()}\n",
    "            <br /><br />\n",
    "            <h2>Arguments </h2>\n",
    "            {params.to_html()}\n",
    "            \"\"\", file=f)\n",
    "\n",
    "def shift_to_other(this, other, this_range=None, this_center=None):\n",
    "    u = other.mean()\n",
    "    r = other.std()#other.max()-other.min()\n",
    "\n",
    "    if this_range is None:\n",
    "        this_range = this.std()#this.max()-this.min()\n",
    "\n",
    "    if this_center is None:\n",
    "        this_center = this.mean()\n",
    "    return (this-this_center)/(this_range)*r+u\n",
    "\n",
    "perf_col = performance_col\n",
    "perf_df = combined_df[perf_col]\n",
    "perf_df\n",
    "other_cols = column_xs(combined_df, exclude=['performance', 'count'])\n",
    "other_df = combined_df[other_cols]\n",
    "other_df\n",
    "extra_valids = pd.DataFrame(columns=other_df.columns)\n",
    "extra_perf = pd.DataFrame(columns=perf_df.name)\n",
    "\n",
    "extra_perf\n",
    "cxs = column_xs(other_df, include=stat)\n",
    "stats = pd.concat([other_df[cxs].dropna(axis=1), extra_valids[cxs].dropna(axis=1)], axis=0).sort_index()\n",
    "\n",
    "\n",
    "stats = stats.loc[standardize_ix]\n",
    "\n",
    "print(len(stats))\n",
    "stats = stats.agg([\"mean\", \"std\"])\n",
    "\n",
    "\n",
    "stats.T\n",
    "\n",
    "otherstd = other_df[cxs].copy()\n",
    "\n",
    "# cannot divide by zero\n",
    "std0 = stats.loc['std'] == 0\n",
    "stats.loc[\"std\", stats.loc['std'] == 0] = 1\n",
    "otherstd = (otherstd-stats.loc['mean'])/(stats.loc[\"std\"])\n",
    "errorstd = (error_df[cxs]-stats.loc['mean'])/(stats.loc[\"std\"])\n",
    "bad_cols = otherstd.columns[otherstd.isnull().max(axis=0)].tolist()\n",
    "\n",
    "print(bad_cols)\n",
    "\n",
    "vae_cols = [c for c in list(otherstd) if \"mu.\" in c[0]]\n",
    "score_cols = [c for c in list(otherstd) if \"activation.\" in c[0]]\n",
    "metadata_cols = sorted(set(otherstd).difference(vae_cols).difference(score_cols))\n",
    "\n",
    "if clip is not None:\n",
    "  otherstd = otherstd.clip(-1*clip, clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.date_range(combined_df.index.min(), combined_df.index.max())\n",
    "yp = combined_df[perf_col].reindex(x)\n",
    "perf_error_df = error_df[perf_col].reindex(x)\n",
    "\n",
    "all_corr_df = correlate_performance(yp.rename('auroc'), otherstd)\n",
    "all_ig_df = mutual_info_performance(yp.rename('auroc'), otherstd, bins=25)\n",
    "\n",
    "m_ = all_ig_df.to_frame().join(all_corr_df.abs().rename('abs(corr)'))\n",
    "m_ = m_.join(m_.mean(axis=1).rename('mean[abs(corr),info_gain]'))\n",
    "m_ = m_.assign(no_weights=1)\n",
    "m_ = m_.fillna(0)\n",
    "m_.sort_values(by='mean[abs(corr),info_gain]', ascending=False).head(20)\n",
    "\n",
    "true_counts = combined_df_o['count'].droplevel([0, 1], axis=1)['obs']\n",
    "count_df = combined_df['count'].reindex(x)\n",
    "dates = {\"Laterals Injected\": run_row['nonfrontal_add_date'],\n",
    "         \"Frontals Removed\": run_row['frontal_remove_date'],\n",
    "         \"Peds Added\": run_row['peds_start_date'],\n",
    "         \"Peds Stop\": run_row['peds_end_date'],\n",
    "         \"Val Start\": settings.PADCHEST_SPLIT_DATES[0],\n",
    "        #  \"Test Start\": settings.PADCHEST_SPLIT_DATES[1],\n",
    "         }\n",
    "\n",
    "x = x[x<graph_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_names = {\"no_weights\": r\"$MMC$\", \"abs(corr)\": r\"$MMC_w$\",}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = m_.copy()\n",
    "\n",
    "yp = yp.reindex(x)\n",
    "otherstd = otherstd.reindex(x)\n",
    "counts = combined_df['count'].iloc[:, 0].reindex(x)\n",
    "counts2 = true_counts.reindex(x)\n",
    "\n",
    "#collect_corr(y, yp, name, when, weights_name, start_date=None, end_date=None)\n",
    "row=1\n",
    "fh = FigureHelper(x)\n",
    "# fh.add_trace(y=combined_df['count'].iloc[:, 0], name=\"Num Samples (used)\", line={\"color\": \"green\"}, row=4, col=1)\n",
    "# fh.add_trace(y=combined_df['count'].iloc[:, 0], name=\"Num Samples (used)\", kind=go.Bar, row=4, col=1)\n",
    "# fh.add_trace(y=true_counts, name=\"Num Samples (obs)\", line={\"color\": \"orange\"}, row=4, col=1)\n",
    "# fh.add_trace(y=true_counts, name=\"Num Samples (obs)\", kind=go.Bar, row=4, col=1)\n",
    "fh.add_trace(y=smooth(yp), name=\"AUROC\", connectgaps=False, line={\"color\": \"blue\"}, \n",
    "             yu=smooth(yp+perf_error_df.reindex(x)), \n",
    "             yl=smooth(yp-perf_error_df.reindex(x)),\n",
    "             row=row, col=1)\n",
    "# row += 1\n",
    "# fh.add_trace(y=smooth(combined_df[congruency_measure_col]*100), row=row, name='% In-distr.', line={\"color\": \"purple\"})\n",
    "row += 1\n",
    "\n",
    "corrs = []\n",
    "corrs.append(collect_corr(counts,yp, \"num sampled (used)\", \"Everything\", \"None\"))\n",
    "corrs.append(collect_corr(counts,yp, \"num sampled (used)\", \"Validation\", \"None\",\n",
    "                            start_date=settings.PADCHEST_SPLIT_DATES[0], end_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "corrs.append(collect_corr(counts,yp, \"num sampled (used)\", \"Test\", \"None\",\n",
    "                        start_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "corrs.append(collect_corr(counts,yp, \"num sampled (used)\", \"First Year of Test\", \"None\",\n",
    "                        start_date=settings.PADCHEST_SPLIT_DATES[1], end_date=\"2014-12-31\"))\n",
    "\n",
    "corrs.append(collect_corr(counts2,yp, \"num sampled (obs)\", \"Everything\",\"None\"))\n",
    "corrs.append(collect_corr(counts2,yp, \"num sampled (obs)\", \"Validation\", \"None\",\n",
    "                            start_date=settings.PADCHEST_SPLIT_DATES[0], end_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "corrs.append(collect_corr(counts2,yp, \"num sampled (obs)\", \"Test\", \"None\",\n",
    "                        start_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "corrs.append(collect_corr(counts2,yp, \"num sampled (obs)\", \"First Year of Test\", \"None\",\n",
    "                        start_date=settings.PADCHEST_SPLIT_DATES[1], end_date=\"2014-12-31\"))\n",
    "\n",
    "errorstd = errorstd[otherstd.columns]\n",
    "\n",
    "for i, (name, vname) in enumerate(weight_names.items()):\n",
    "    weights = m_[name].sort_values(ascending=False)\n",
    "    # weights = weights.iloc[:5]\n",
    "    y = -w_avg(otherstd.reindex(x), weights=weights.to_dict())\n",
    "    ystd = -w_avg(errorstd.reindex(x), weights=weights.to_dict())\n",
    "    fh.add_trace(y=smooth(y),\n",
    "                        # customdata=smooth(yo),\n",
    "                        showlegend=True, legendgroup=vname,\n",
    "                        name=vname,  \n",
    "                        connectgaps=False, row=row, col=1)\n",
    "    \n",
    "    corrs.append(collect_corr(y,yp, \"All Unified\", \"Everything\", vname))\n",
    "    corrs.append(collect_corr(y,yp, \"All Unified\", \"Validation\", vname,\n",
    "                              start_date=settings.PADCHEST_SPLIT_DATES[0], end_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "    corrs.append(collect_corr(y,yp, \"All Unified\", \"Test\", vname,\n",
    "                            start_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "    corrs.append(collect_corr(y,yp, \"All Unified\", \"First Year of Test\", vname,\n",
    "                            start_date=settings.PADCHEST_SPLIT_DATES[1], end_date=\"2014-12-31\"))\n",
    "\n",
    "\n",
    "corr_df = pd.DataFrame(corrs).sort_values('when')\n",
    "display(corr_df)\n",
    "# display(HTML(\"\"\"<script async=\"async\" src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML\"></script>\n",
    "#     <script type=\"text/x-mathjax-config\">MathJax.Hub.Config({\"tex2jax\": {\"inlineMath\": [[\"$\", \"$\"], [\"\\\\(\", \"\\\\)\"]], \"processEscapes\": true, \"ignoreClass\": \"document\", \"processClass\": \"math|output_area\"}})</script>\"\"\"))\n",
    "\n",
    "fig = fh.make_fig(shared_xaxes=True, vertical_spacing=0.025, row_heights=[.2]*row)\n",
    "add_dates(fig, dates, line_y=1.045, include_date=False)\n",
    "fig.update_xaxes(showspikes=True, spikecolor=\"black\", spikesnap=\"cursor\", spikemode=\"across\", spikethickness=1)\n",
    "fig.update_layout(spikedistance=1000)\n",
    "fig.update_layout(height=200*row)\n",
    "fig.update_layout(legend={\"x\": .35, \"orientation\":\"h\", \"borderwidth\": .5})\n",
    "fig.update_xaxes(range=[graph_start, graph_end])\n",
    "fig.update_layout(barmode='overlay')\n",
    "fig.update_layout(font=dict(size=13))\n",
    "fig.update_layout(plot_bgcolor=\"#E8E8EA\")\n",
    "\n",
    "fig.update_layout(\n",
    "    yaxis2 = dict(\n",
    "        tickmode = 'linear',\n",
    "        tick0 = 0,\n",
    "        dtick = 25,\n",
    "    )\n",
    ")\n",
    "\n",
    "xaxis = dict(\n",
    "        tickformat = '%Y-%m-%d',\n",
    "        tickmode = 'linear',\n",
    "        dtick = \"M1\"\n",
    "    )\n",
    "fig.update_layout(\n",
    "    xaxis1=xaxis,\n",
    "    xaxis2=xaxis,\n",
    "    xaxis3 = xaxis,\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "if False: \n",
    "    with open(fn, 'a') as f:\n",
    "        fig_html = fig.to_html()\n",
    "        print(f\"<h2>Full Unified</h2>\", file=f)\n",
    "        for w, grp in corr_df.groupby('when'):\n",
    "            print(f\"<strong>{w}</strong>{grp.to_html()}\", file=f)\n",
    "        print(fig_html, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "\n",
    "fname = html_top_dir.joinpath(verbose_name+'.svg')\n",
    "pio.write_image(fig, html_top_dir.joinpath(verbose_name+'.svg'), scale=1, width=5*300, height=2*300)\n",
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "relfname = os.path.relpath(str(fname), os.getcwd())\n",
    "display(HTML(f\"\"\"<img src=\"{relfname}\" />\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "auroc_cols = column_xs(combined_df, ['auroc'])\n",
    "precision_cols = column_xs(combined_df, ['precision'])\n",
    "recall_cols = column_xs(combined_df, ['recall'])\n",
    "f1_cols = column_xs(combined_df, ['f1-score'])\n",
    "support_cols = column_xs(combined_df, ['support'])\n",
    "\n",
    "cols_ = [auroc_cols, recall_cols, precision_cols, f1_cols, support_cols]\n",
    "fig = make_subplots(rows=len(cols_), cols=1, shared_xaxes=True, vertical_spacing=0.01)\n",
    "\n",
    "names = sorted(set([c[1] for c in itertools.chain(*cols_)]), key=lambda x: 'avg' in x)\n",
    "colors = px.colors.qualitative.Plotly\n",
    "dashes = ['solid', 'dash', 'dotted']\n",
    "\n",
    "list(itertools.product(dashes, colors))\n",
    "\n",
    "lines = {}\n",
    "for name, spec in zip(names, itertools.product(dashes, colors)):\n",
    "    lines[name] = {'color': spec[1], 'dash': spec[0]}\n",
    "\n",
    "visited = set()\n",
    "for r, cols__ in enumerate(cols_, 1):\n",
    "    for c in cols__:\n",
    "        ypp = combined_df[c].reindex(x)\n",
    "        line = lines[c[1]]\n",
    "        showlegend = not c[1] in visited\n",
    "        visited.add(c[1])\n",
    "        fig.add_trace(go.Scatter(x=x, y=smooth(ypp), showlegend=showlegend, legendgroup=c[1],\n",
    "                name=c[1], hovertemplate=\"%{y: .5f}\", connectgaps=False, line=line), row=r, col=1)\n",
    "    fig.update_yaxes(title_text=c[-1], row=r, col=1)\n",
    "add_dates(fig, dates, 1.025)\n",
    "\n",
    "fig.update_layout(title=f\"Peformance\")\n",
    "fig.update_layout(hovermode=\"x unified\")\n",
    "fig.update_layout(height=300*len(cols_))\n",
    "fig.update_xaxes(range=[graph_start, graph_end])\n",
    "fig.update_layout(font=font)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "if write_html:\n",
    "    fig_html = fig.to_html()\n",
    "    with open(fn, 'a') as f:\n",
    "        print(f\"<h2>Performance</h2>\", file=f)\n",
    "        print(fig_html, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = FigureHelper(x)\n",
    "fh.add_trace(y=smooth(yp), name=\"AUROC\", connectgaps=False, line={\"color\": \"blue\"}, yu=smooth(yp+perf_error_df), yl=smooth(yp-perf_error_df), row=1, col=1)\n",
    "fh.add_trace(y=smooth(combined_df[congruency_measure_col]), row=2, name='Data Congruency (True)')\n",
    "corrs = []\n",
    "\n",
    "if not float(run_row['peds_weight']):\n",
    "    xcols = zip([\"metadata\", \"vae\", \"score\", \"vae+score\", \"metadate+vae+score\"],  [metadata_cols, vae_cols, score_cols, vae_cols+score_cols, vae_cols+score_cols+metadata_cols])\n",
    "else:\n",
    "    xcols = zip([\"vae\", \"score\", \"vae+score\"],  [vae_cols, score_cols, vae_cols+score_cols])\n",
    "\n",
    "for row, (name_, cols) in enumerate(xcols, 1):\n",
    "    for i, name in enumerate([\"abs(corr)\"]):\n",
    "        otherstd_ = otherstd[cols]\n",
    "        weights = m[name].sort_values(ascending=False)\n",
    "        yo = -w_avg(otherstd_.loc[x], weights=weights.to_dict())\n",
    "        \n",
    "        fh.add_trace(y=smooth(yo), name=name_, line={\"width\": 1},  connectgaps=False, row=3, col=1)\n",
    "        \n",
    "        corrs.append(collect_corr(y,yo, name_, \"Everything\", name))\n",
    "        corrs.append(collect_corr(y,yo, name_, \"Validation\", name,\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[0], end_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "        corrs.append(collect_corr(y,yo, name_, \"Test\", name,\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "        corrs.append(collect_corr(y,yo, name_, \"First Year of Test\", name,\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[1], end_date=\"2014-12-31\"))\n",
    "\n",
    "\n",
    "fig = fh.make_fig(shared_xaxes=True, vertical_spacing=0.01)\n",
    "add_dates(fig, dates, 1.08)\n",
    "\n",
    "\n",
    "fig.update_layout(title=f\"Level 1 Metrics\")\n",
    "fig.update_xaxes(showspikes=True, spikecolor=\"black\", spikesnap=\"cursor\", spikemode=\"across\", spikethickness=1)\n",
    "fig.update_layout(spikedistance=1000)\n",
    "fig.update_layout(height=600)\n",
    "fig.update_xaxes(range=[graph_start, graph_end])\n",
    "fig.update_layout(barmode='overlay')\n",
    "corr_df = pd.DataFrame(corrs).sort_values('when')\n",
    "display(corr_df)\n",
    "fig.show()\n",
    "\n",
    "fig_html = fig.to_html()\n",
    "\n",
    "if write_html:\n",
    "    with open(fn, 'a') as f:\n",
    "        print(f\"<h2>Level 1 Unified</h2>\", file=f)\n",
    "        for w, grp in corr_df.groupby('when'):\n",
    "            print(f\"<strong>{w}</strong>{grp.to_html()}\", file=f)\n",
    "        print(fig_html, file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = FigureHelper(x, dashes=['solid', 'dot', 'dash', 'longdash', 'dashdot', 'longdashdot'])\n",
    "fh.add_trace(y=smooth(yp), name=\"AUROC\", connectgaps=False, line={\"color\": \"blue\"}, yu=smooth(yp+perf_error_df), yl=smooth(yp-perf_error_df), row=1, col=1)\n",
    "fh.add_trace(y=smooth(combined_df[congruency_measure_col]), row=2, name='Data Congruency (True)')\n",
    "corrs = []\n",
    "\n",
    "def partition(l, n):\n",
    "    return [l[i:i + n] for i in range(0, len(l), n)]\n",
    "\n",
    "cols = metadata_cols\n",
    "otherstd_ = otherstd[cols]\n",
    "cols_chi2 = column_xs(otherstd_, include='chi2')\n",
    "otherstd_ = otherstd[cols_chi2]\n",
    "cols_ = partition(cols_chi2, 12)\n",
    "print(len(cols_))\n",
    "\n",
    "for row, cols in enumerate(cols_, 3):\n",
    "    for c in cols:\n",
    "        yo = -otherstd[c]\n",
    "        fh.add_trace(y=smooth(yo), name=str(c), connectgaps=False, row=row, col=1)\n",
    "        \n",
    "        corrs.append(collect_corr(y,yo, str(c), \"Everything\", 'N/A'))\n",
    "        corrs.append(collect_corr(y,yo, str(c), \"Validation\", 'N/A',\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[0], end_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "        corrs.append(collect_corr(y,yo, str(c), \"Test\", 'N/A',\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "        corrs.append(collect_corr(y,yo, str(c), \"First Year of Test\", 'N/A',\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[1], end_date=\"2014-12-31\"))\n",
    "\n",
    "if not float(run_row['peds_weight']):     \n",
    "    fig = fh.make_fig(shared_xaxes=True, vertical_spacing=0.01)\n",
    "    add_dates(fig, dates, 1.05)\n",
    "\n",
    "    fig.update_layout(title=f\"Metadata Categorical\")\n",
    "    fig.update_xaxes(showspikes=True, spikecolor=\"black\", spikesnap=\"cursor\", spikemode=\"across\", spikethickness=1)\n",
    "    fig.update_layout(spikedistance=1000)\n",
    "    fig.update_layout(height=200*(len(cols_)+2))\n",
    "    fig.update_xaxes(range=[graph_start, graph_end])\n",
    "    fig.update_layout(font=font)\n",
    "    fig.update_layout(barmode='overlay')\n",
    "\n",
    "    corr_df = pd.DataFrame(corrs)\n",
    "    display(corr_df)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "    fig_html = fig.to_html()\n",
    "    if write_html: \n",
    "        with open(fn, 'a') as f:\n",
    "            print(f\"<h2>Metadata Categorical</h2>\", file=f)\n",
    "            for w, grp in corr_df.groupby('when'):\n",
    "                print(f\"<strong>{w}</strong>{grp.to_html()}\", file=f)\n",
    "            print(fig_html, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = FigureHelper(x, dashes=['solid', 'dot', 'dash', 'longdash', 'dashdot', 'longdashdot'])\n",
    "fh.add_trace(y=smooth(yp), name=\"AUROC\", connectgaps=False, line={\"color\": \"blue\"}, yu=smooth(yp+perf_error_df), yl=smooth(yp-perf_error_df), row=1, col=1)\n",
    "fh.add_trace(y=smooth(combined_df[congruency_measure_col]), row=2, name='Data Congruency (True)')\n",
    "corrs = []\n",
    "\n",
    "def partition(l, n):\n",
    "    return [l[i:i + n] for i in range(0, len(l), n)]\n",
    "\n",
    "cols = metadata_cols\n",
    "otherstd_ = otherstd[cols]\n",
    "cols_chi2 = column_xs(otherstd_, include='ks')\n",
    "otherstd_ = otherstd[cols_chi2]\n",
    "cols_ = partition(cols_chi2, 14)\n",
    "print(len(cols_chi2))\n",
    "\n",
    "for row, cols in enumerate(cols_, 3):\n",
    "    for c in cols:\n",
    "        yo = -otherstd[c]\n",
    "        fh.add_trace(y=smooth(yo), name=str(c), connectgaps=False, row=row, col=1)\n",
    "        \n",
    "        corrs.append(collect_corr(y,yo, str(c), \"Everything\", 'N/A'))\n",
    "        corrs.append(collect_corr(y,yo, str(c), \"Validation\", 'N/A',\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[0], end_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "        corrs.append(collect_corr(y,yo, str(c), \"Test\", 'N/A',\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "        corrs.append(collect_corr(y,yo, str(c), \"First Year of Test\", 'N/A',\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[1], end_date=\"2014-12-31\"))\n",
    "if not float(run_row['peds_weight']):\n",
    "    fig = fh.make_fig(shared_xaxes=True, vertical_spacing=0.01)\n",
    "    add_dates(fig, dates, 1.08)\n",
    "\n",
    "    fig.update_layout(title=f\"Metadata Real Valued\")\n",
    "    fig.update_xaxes(showspikes=True, spikecolor=\"black\", spikesnap=\"cursor\", spikemode=\"across\", spikethickness=1)\n",
    "    fig.update_layout(spikedistance=1000)\n",
    "    fig.update_layout(height=200*(len(cols_)+2))\n",
    "    fig.update_xaxes(range=[graph_start, graph_end])\n",
    "    fig.update_layout(font=font)\n",
    "    fig.update_layout(barmode='overlay')\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "    fig_html = fig.to_html()\n",
    "    if write_html: \n",
    "        with open(fn, 'a') as f:\n",
    "            print(f\"<h2>Metadata Real Valued</h2>\", file=f)\n",
    "            for w, grp in corr_df.groupby('when'):\n",
    "                print(f\"<strong>{w}</strong>{grp.to_html()}\", file=f)\n",
    "            print(fig_html, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = FigureHelper(x, dashes=['solid', 'dot', 'dash', 'longdash', 'dashdot', 'longdashdot'])\n",
    "fh.add_trace(y=smooth(yp), name=\"AUROC\", connectgaps=False, line={\"color\": \"blue\"}, yu=smooth(yp+perf_error_df), yl=smooth(yp-perf_error_df), row=1, col=1)\n",
    "fh.add_trace(y=smooth(combined_df[congruency_measure_col]), row=2, name='Data Congruency (True)')\n",
    "corrs = []\n",
    "\n",
    "def partition(l, n):\n",
    "    return [l[i:i + n] for i in range(0, len(l), n)]\n",
    "\n",
    "\n",
    "cols = vae_cols\n",
    "o = other_df[cols].loc[settings.PADCHEST_SPLIT_DATES[1]:].swaplevel(0, 2, axis=1)[['distance']].swaplevel(0, 2, axis=1)\n",
    "colss = o.max(axis=0).sort_values(ascending=False).head(12).index.tolist()\n",
    "cols_ = partition(colss, 12)\n",
    "\n",
    "\n",
    "for row, cols in enumerate(cols_, 3):\n",
    "    for c in cols:\n",
    "        yo = -otherstd[c]\n",
    "        fh.add_trace(y=smooth(yo), name=str(c), connectgaps=False, row=row, col=1)\n",
    "        \n",
    "        corrs.append(collect_corr(y,yo, str(c), \"Everything\", 'N/A'))\n",
    "        corrs.append(collect_corr(y,yo, str(c), \"Validation\", 'N/A',\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[0], end_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "        corrs.append(collect_corr(y,yo, str(c), \"Test\", 'N/A',\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "        corrs.append(collect_corr(y,yo, str(c), \"First Year of Test\", 'N/A',\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[1], end_date=\"2014-12-31\"))\n",
    "        \n",
    "fig = fh.make_fig(shared_xaxes=True, vertical_spacing=0.01)\n",
    "add_dates(fig, dates, 1.08)\n",
    "\n",
    "fig.update_layout(title=f\"VAE Mu (top {len(colss)})\")\n",
    "fig.update_xaxes(showspikes=True, spikecolor=\"black\", spikesnap=\"cursor\", spikemode=\"across\", spikethickness=1)\n",
    "fig.update_layout(spikedistance=1000)\n",
    "fig.update_layout(height=200*(len(cols_)+2))\n",
    "fig.update_xaxes(range=[settings.PADCHEST_SPLIT_DATES[1], graph_end])\n",
    "fig.update_layout(barmode='overlay')\n",
    "fig.update_layout(font=font)\n",
    "corr_df = pd.DataFrame(corrs).sort_values('when')\n",
    "display(corr_df)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig_html = fig.to_html()\n",
    "if write_html: \n",
    "    with open(fn, 'a') as f:\n",
    "        print(f\"<h2>VAE Mu (top {len(colss)})</h2>\", file=f)\n",
    "        for w, grp in corr_df.groupby('when'):\n",
    "            print(f\"<strong>{w}</strong>{grp.to_html()}\", file=f)\n",
    "        print(fig_html, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_df2['Link'] = [f\"\"\"<a href=\"{name}/index.html\" disabled=>Graphs</a>\"\"\" if html_top_dir.joinpath(name).exists() else \"N/A\" for name in arg_df2.index]\n",
    "\n",
    "\n",
    "with open(html_top_dir.joinpath(\"index.html\"), 'w') as f:\n",
    "        print(\"\"\"\n",
    "            <style>\n",
    "            table {\n",
    "            font-family: arial, sans-serif;\n",
    "            border-collapse: collapse;\n",
    "            width: 80%;\n",
    "            }\n",
    "\n",
    "            td, th {\n",
    "            border: 1px solid #dddddd;\n",
    "            text-align: left;\n",
    "            padding: 8px;\n",
    "            }\n",
    "\n",
    "            tr:nth-child(even) {\n",
    "            background-color: #dddddd;\n",
    "            }\n",
    "            </style>\n",
    "        \"\"\", file=f)\n",
    "        print(f\"Generated: {datetime.datetime.now()}\", file=f)\n",
    "        print(arg_df2.to_html(escape=False), file=f)\n",
    "        print(fix_links_script, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_html(child):\n",
    "    if child.is_file(): return\n",
    "    html_files = []\n",
    "    html_folders = []\n",
    "    if child.parent.joinpath('index.html').exists():\n",
    "        html_folders.append(\"..\")\n",
    "    for html_file in child.iterdir():\n",
    "        n = html_file.relative_to(child)\n",
    "        if html_file.is_file() and not str(html_file).endswith('index.html'):\n",
    "            html_files.append(n)\n",
    "        elif html_file.joinpath('index.html').exists():\n",
    "            html_folders.append(n)\n",
    "    \n",
    "    \n",
    "    html = \"folders: <ul>\"\n",
    "    for n in html_folders:\n",
    "            html += f\"\"\"\n",
    "            <li><a href=\"{n}/index.html\">{n}</a></li>\n",
    "            \"\"\"\n",
    "    html += \"</ul>\"\n",
    "    html += \"files:<ul>\"\n",
    "    for n in html_files:\n",
    "            html += f\"\"\"\n",
    "            <li><a href=\"{n}\">{n}</a></li>\n",
    "            \"\"\"\n",
    "    html += \"</ul>\"\n",
    "    with open(child.joinpath('index.html'), 'w') as f:\n",
    "        print(html, file=f)\n",
    "        print(fix_links_script, file=f)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_index_html(html_top_dir.parent.joinpath('vae[all-data]'))\n",
    "create_index_html(html_top_dir.parent)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in html_top_dir.iterdir():\n",
    "    create_index_html(child)\n",
    "    \n",
    "            \n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40209cfd1e49aba1e20a3908f9a243f43b2ed73034fd3a81730d62124bbdcdae"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
