{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, HTML\n",
    "import plotly.express as px\n",
    "import itertools\n",
    "\n",
    "from azureml.core import Run, Model\n",
    "from azureml.core import Datastore, Experiment, ScriptRunConfig, Workspace\n",
    "\n",
    "from model_drift import settings\n",
    "from model_drift.helpers import column_xs, correlate_performance, mutual_info_performance, w_avg\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config(settings.AZUREML_CONFIG)\n",
    "\n",
    "experiment_name = 'generate-drift-csv-label-mod-dbg'\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = []\n",
    "for run in exp.get_runs():\n",
    "    if run.status != \"Completed\":\n",
    "        continue\n",
    "    d = dict(**run.tags)\n",
    "    d['id'] = run.id\n",
    "    d['display_name'] = run.display_name\n",
    "    d['url'] = run.get_portal_url()\n",
    "    d['run'] = run\n",
    "    df.append(d)\n",
    "\n",
    "df2 = []\n",
    "experiment_name = 'generate-drift-csv-3'\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "for run in exp.get_runs():\n",
    "    if \"tender_pear_lfbd6wwg\" not in run.display_name:\n",
    "        continue\n",
    "    if run.status != \"Completed\":\n",
    "        continue\n",
    "    print(run.display_name)\n",
    "    d = dict(**run.tags)\n",
    "    d['id'] = run.id\n",
    "    d['display_name'] = run.display_name\n",
    "    d['url'] = run.get_portal_url()\n",
    "    d['run'] = run\n",
    "    d[\"label_modifiers\"] = \"baseline\"\n",
    "    df2.append(d)\n",
    "    \n",
    "df = pd.DataFrame(df).set_index(['display_name'])\n",
    "# df = df.sort_values([\"window\", \"nonfrontal_add_date\", \"frontal_remove_date\", \"peds_weight\"])\n",
    "df = df[~df['mod_end_date'].isnull()]\n",
    "df = pd.concat([pd.DataFrame(df2).set_index(['display_name']), df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_arg_col(c):\n",
    "    if \"mlflow\" in c or \"_aml\" in c or 'run_' in c or 'url' in c:\n",
    "        return False\n",
    "\n",
    "    ignore = [\"output_dir\", \"input_dir\", 'run', 'display_name', 'id']\n",
    "\n",
    "    return c not in ignore\n",
    "arg_cols = [c for c in df.columns if is_arg_col(c)]\n",
    "\n",
    "arg_df = df[arg_cols].query(\"classifier_dataset == 'padchest-finetuned-chx-frontalonly'\").copy()\n",
    "arg_df = arg_df[~arg_df.duplicated(keep='last')]\n",
    "arg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_links_script = \"\"\"\n",
    "              <script>\n",
    "                var x = document.getElementsByTagName('a');\n",
    "                var i;\n",
    "                for (i = 0; i < x.length; i++) {{\n",
    "                    let url = x[i].getAttribute(\"href\");\n",
    "                    x[i].href = url + window.location.search;\n",
    "                }}\n",
    "                </script>\n",
    "              \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_top_dir = settings.TOP_DIR.joinpath(\"html\", \"graphs_label-simple\")\n",
    "html_top_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_df2 =arg_df[[c for c in arg_df if arg_df[c].fillna('NA').nunique() > 1]]\n",
    "arg_df2['Link'] = [f\"\"\"<a href=\"{name}/index.html\" disabled=>Graphs</a>\"\"\" if html_top_dir.joinpath(name).exists() else \"N/A\" for name in arg_df2.index]\n",
    "\n",
    "with open(html_top_dir.joinpath(\"index.html\"), 'w') as f:\n",
    "        print(\"\"\"\n",
    "            <style>\n",
    "            table {\n",
    "            font-family: arial, sans-serif;\n",
    "            border-collapse: collapse;\n",
    "            width: 80%;\n",
    "            }\n",
    "\n",
    "            td, th {\n",
    "            border: 1px solid #dddddd;\n",
    "            text-align: left;\n",
    "            padding: 8px;\n",
    "            }\n",
    "\n",
    "            tr:nth-child(even) {\n",
    "            background-color: #dddddd;\n",
    "            }\n",
    "            </style>\n",
    "            <br />\n",
    "        \"\"\", file=f)\n",
    "        print(f\"pre Generated: {datetime.datetime.now()}\", file=f)\n",
    "        print(arg_df2.to_html(escape=False), file=f)\n",
    "        print(fix_links_script, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.loc[arg_df.index]\n",
    "\n",
    "arg_df2.loc[[not html_top_dir.joinpath(name).exists() for name in df.index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_row = df.loc[[not html_top_dir.joinpath(name).exists() for name in df.index]].iloc[0]\n",
    "# run_row = df.loc[\"affable_parang_mhjpv4b2\"]\n",
    "\n",
    "r = run_row['run']\n",
    "name = run_row.name\n",
    "\n",
    "\n",
    "print(name)\n",
    "# Diplay settings\n",
    "span = 7\n",
    "which = 'mean'\n",
    "clip = 10\n",
    "\n",
    "performance_col = (\"performance\", \"macro avg\", \"auroc\")\n",
    "\n",
    "congruency_measure_col = ('in_distro', 'stats', 'mean')\n",
    "add_error_bars = True\n",
    "\n",
    "standardize_dates = (settings.PADCHEST_SPLIT_DATES[0], settings.PADCHEST_SPLIT_DATES[1])\n",
    "standardize_ix = pd.date_range(*standardize_dates)\n",
    "stat = []\n",
    "# stat.append('pval')\n",
    "stat.append('distance')\n",
    "\n",
    "write_html = True\n",
    "show_corr = False\n",
    "graph_start = \"2014-01-01\"\n",
    "graph_end = \"2014-12-31\"\n",
    "drop_modality = False\n",
    "\n",
    "font=dict(size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from matplotlib import colors as mpl_colors\n",
    "from collections import defaultdict\n",
    "\n",
    "def to_rgba(rgb, alpha=None):\n",
    "    rgb = mpl_colors.to_rgb(rgb)\n",
    "    if alpha is None:\n",
    "        return \"rgb(%s, %s, %s)\" % (rgb[0], rgb[1], rgb[2])\n",
    "    return \"rgba(%s, %s, %s, %s)\" % (rgb[0], rgb[1], rgb[2], alpha)\n",
    "\n",
    "def line_maker(color, **l):\n",
    "    return dict(color=color, **l)\n",
    "\n",
    "def marker_maker(color, **l):\n",
    "    return dict(color=color)\n",
    "\n",
    "def smooth(y: pd.DataFrame):\n",
    "    if span > 0:\n",
    "        ys = y.ewm(span=span, ignore_na=False).mean()\n",
    "        ys[y.isna()] = None\n",
    "    else:\n",
    "        ys = y    \n",
    "    return ys\n",
    "\n",
    "def add_date_line(fig, date, name, y=1.08):\n",
    "    fig.add_shape(type='line',\n",
    "                x0=date,\n",
    "                y0=0,\n",
    "                x1=date,\n",
    "                y1=1,\n",
    "                line=dict(color='black', dash='dot'),\n",
    "                xref='x',\n",
    "                yref='paper'\n",
    "                )\n",
    "    fig.add_annotation(textangle=0,\n",
    "                    xref=\"x\",\n",
    "                    yref=\"paper\", x=date, y=y,\n",
    "                       text=name, showarrow=False,)\n",
    "\n",
    "def add_dates(fig, dates, line_y=1.05):\n",
    "    \n",
    "    dates_rev = defaultdict(list)\n",
    "    for name, date in dates.items():\n",
    "        dates_rev[date].append(name)\n",
    "    \n",
    "    for date, names in dates_rev.items():\n",
    "        name = \"<br>\".join(names)\n",
    "        if not pd.isna(date):\n",
    "            add_date_line(fig, date, f\"{name}<br />({date})\", y=line_y)\n",
    "            \n",
    "def collect_corr(y, yp, name, when, weights_name, start_date=None, end_date=None):\n",
    "    yp = yp.loc[start_date: end_date]\n",
    "    y = y.loc[start_date: end_date]\n",
    "    c, cm = yp.corr(y), smooth(yp).corr(smooth(y))\n",
    "    return {\"name\": name, \"weights_name\": weights_name,\n",
    "                \"corr (raw)\": c, \"corr (smoothed)\": cm, \"when\": when}\n",
    "\n",
    "class FigureHelper(object):\n",
    "    \n",
    "    def __init__(self, x=None, color_list=px.colors.qualitative.Plotly, dashes=('solid',), smooth_func=smooth, merge_hover=True):\n",
    "        self.traces = []\n",
    "        self.error_traces = []\n",
    "        self.color_list = color_list\n",
    "        self.line_picker = itertools.cycle(itertools.product(dashes, self.color_list))\n",
    "        self.lines = defaultdict(lambda: dict(zip(['dash', 'color'], next(self.line_picker))))\n",
    "        self.names = set()\n",
    "        self.smooth = smooth_func\n",
    "        self.x = x\n",
    "        self.merge_hover = merge_hover\n",
    "        \n",
    "    def set_line(self, key, line=None):\n",
    "        line = line or {}\n",
    "        self.lines[key] = self.lines[key]\n",
    "        self.lines[key].update(line)\n",
    "        self.lines[key]['color'] = self.lines[key]['color']\n",
    "        return self.lines[key]\n",
    "        \n",
    "        \n",
    "    def make_error_traces(self, x, yu, yl, name, color, alpha):\n",
    "        \n",
    "        \n",
    "        # need to remove nans from error traces\n",
    "        k = ~(yu.isnull()|yl.isnull())\n",
    "        xe = x[k]\n",
    "        yl = yl[k]\n",
    "        yu = yu[k]\n",
    "        \n",
    "        return [go.Scatter(x=xe, \n",
    "                            y=yu, \n",
    "                            hoverinfo=\"skip\",\n",
    "                            showlegend=False,\n",
    "                            legendgroup=name,\n",
    "                            name=name,\n",
    "                            connectgaps=False,\n",
    "                            line=dict(width=0),\n",
    "                ), \n",
    "                go.Scatter(x=xe, \n",
    "                            y=yl,\n",
    "                            fillcolor=to_rgba(color, alpha),\n",
    "                            fill='tonexty',\n",
    "                            hoverinfo=\"skip\",\n",
    "                            showlegend=False,                            \n",
    "                            legendgroup=name,\n",
    "                            name=name,\n",
    "                            connectgaps=False,\n",
    "                            line=dict(width=0),\n",
    "                )]\n",
    "\n",
    "    def add_trace(self, y, name, x=None, kind=go.Scatter, color_key=None, row=1, col=1, line=None,\n",
    "                  std=None, yu=None, yl=None, **trace_kwargs):\n",
    "        color_key = color_key or name\n",
    "        trace_kwargs.setdefault('showlegend', name not in self.names)\n",
    "        self.names.add(name)\n",
    "        trace_kwargs.setdefault('legendgroup', name)\n",
    "        \n",
    "        line = self.set_line(color_key, line)\n",
    "        x = x or self.x\n",
    "        y = y.reindex(x)\n",
    "        t = kind(x=x, y=y, name=name, **trace_kwargs)\n",
    "        if not isinstance(t, go.Bar):\n",
    "            t.line = line_maker(**line)\n",
    "        else:\n",
    "            t.marker = marker_maker(**line)\n",
    "            \n",
    "    \n",
    "        self.traces.append((row, col, t))\n",
    "        \n",
    "        if std is not None:\n",
    "            yu = y+std\n",
    "            yl = y-std\n",
    "            \n",
    "        if yu is not None and yl is not None:\n",
    "            for t_ in self.make_error_traces(x, yu, yl, name=name, color=line[\"color\"], alpha=0.2):\n",
    "                self.error_traces.append((row, col, t_))\n",
    "    \n",
    "    \n",
    "    def add_bar(self, y, name, x=None, color_key=None, row=1, col=1, line=None, include_line=True,\n",
    "                **trace_kwargs):\n",
    "        \n",
    "        if include_line:\n",
    "            self.add_trace(y=y, name=name, color_key=color_key, line=line, row=row, col=col, **trace_kwargs)\n",
    "        self.add_trace(y=y, name=name, color_key=color_key, kind=go.Bar, line=line, row=row, col=col, **trace_kwargs)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def make_fig(self, **fig_kwargs):\n",
    "\n",
    "        data = {}\n",
    "        max_row = 1\n",
    "        max_col = 1\n",
    "        for r, c, t in self.traces:\n",
    "            max_row = max(r, max_row)\n",
    "            max_col = max(c, max_col)\n",
    "            data[t.name] = pd.Series(t.y, index=t.x)\n",
    "            \n",
    "        customdata = pd.DataFrame(data)\n",
    "        fig = make_subplots(rows=max_row, cols=max_col, **fig_kwargs)\n",
    "        for r, c, t in self.traces:\n",
    "            if self.merge_hover:\n",
    "                cus_cols = sorted(customdata)\n",
    "                ho = \"<br />\".join([\"{name}=%{{customdata[{i}]:.3f}}\".format(i=i, name=name) for i,name in enumerate(cus_cols)])\n",
    "                hovertemplate = \"%{x}<br>\" + f\"{t.name}: \" +\"%{y}<br><br>\"+f\"{ho}<extra></extra>\"\n",
    "                t.customdata = customdata[cus_cols]\n",
    "                t.hovertemplate = hovertemplate\n",
    "            # t.hoverlabel = {'bgcolor': 'white'}\n",
    "            fig.add_trace(t, row=r, col=c)\n",
    "                        \n",
    "        for r, c, t in self.error_traces:\n",
    "            fig.add_trace(t, row=r, col=c)\n",
    "        return fig\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_arg_col(c):\n",
    "    if \"mlflow\" in c or \"_aml\" in c or 'run_' in c or 'url' in c:\n",
    "        return False\n",
    "\n",
    "    ignore = [\"output_dir\", \"input_dir\", 'run', 'display_name', 'id']\n",
    "\n",
    "    return c not in ignore\n",
    "arg_cols = [c for c in df.columns if is_arg_col(c)]\n",
    "arg_row = run_row[arg_cols].copy()\n",
    "\n",
    "arg_row\n",
    "output_file_path = settings.TOP_DIR.joinpath('results', 'drift', name+\".csv\")\n",
    "fname = str(output_file_path)\n",
    "r.download_file(\"outputs/output.csv\", output_file_path=output_file_path)\n",
    "# # Settings to file CSV file\n",
    "\n",
    "display_args = [\"span\", \"which\", \"clip\", \"standardize_perf\", \"shift_drift_to_perf\", \"performance_col\", \"this_center\", \"this_range\", \"standardize_dates\", \"stat\", \"add_error_bars\", \"drop_modality\"]\n",
    "d = locals()\n",
    "display_args = {k: d[k] for k in display_args if k in d}\n",
    "\n",
    "print(display_args)\n",
    "\n",
    "\n",
    "if not os.path.exists(fname):\n",
    "    raise ValueError(\"no fn\")\n",
    "\n",
    "combined_df_o = pd.read_csv(str(fname), index_col=0, header=[0, 1, 2, 3])\n",
    "combined_df_o.index = pd.to_datetime(combined_df_o.index)\n",
    "\n",
    "flip = column_xs(combined_df_o, include=[\"pval\"])\n",
    "combined_df_o[flip] = 1-combined_df_o[flip]\n",
    "combined_df = combined_df_o.copy()\n",
    "\n",
    "\n",
    "smooth_name = f\"ewm{span}\"\n",
    "\n",
    "error_df = combined_df.swaplevel(0, -1, axis=1)[[\"std\"]].swaplevel(0, -1, axis=1).droplevel(-1, axis=1).copy()\n",
    "combined_df = combined_df.swaplevel(0, -1, axis=1)[[which]].swaplevel(0, -1, axis=1).droplevel(-1, axis=1).copy()\n",
    "\n",
    "html_dir = html_top_dir.joinpath(name)\n",
    "perf_col_name = '-'.join(performance_col)\n",
    "\n",
    "if not os.path.exists(html_dir):\n",
    "    os.makedirs(html_dir)\n",
    "\n",
    "stat_str = '+'.join(stat)\n",
    "fn = f\"{html_dir}/{which}_{stat_str}_stdclip{clip}_smooth-{smooth_name}-dropModality{drop_modality}_{perf_col_name}.html\"\n",
    "\n",
    "print(\"output:\", fn)\n",
    "def is_arg_col(c):\n",
    "    if \"mlflow\" in c or \"_aml\" in c or 'run_' in c or 'url' in c:\n",
    "        return False\n",
    "\n",
    "    ignore = [\"output_dir\", \"input_dir\", 'run', 'display_name', 'id']\n",
    "    return c not in ignore\n",
    "\n",
    "arg_row = run_row[arg_cols].copy()\n",
    "display_row = pd.Series(display_args)\n",
    "params = pd.concat({'Drift': arg_row, \"Display\": display_row}, axis=0).rename(\"Value\").to_frame()\n",
    "\n",
    "if write_html:\n",
    "    with open(fn, 'w') as f:\n",
    "        print(\"\"\"\n",
    "            <style>\n",
    "            table {\n",
    "            font-family: arial, sans-serif;\n",
    "            border-collapse: collapse;\n",
    "            width: 80%;\n",
    "            }\n",
    "\n",
    "            td, th {\n",
    "            border: 1px solid #dddddd;\n",
    "            text-align: left;\n",
    "            padding: 8px;\n",
    "            }\n",
    "\n",
    "            tr:nth-child(even) {\n",
    "            background-color: #dddddd;\n",
    "            }\n",
    "            </style>\n",
    "        \"\"\", file=f)\n",
    "        print(f\"\"\"\n",
    "            <h1>Drift report</h1> created: {datetime.datetime.now()}\n",
    "            <br /><br />\n",
    "            <h2>Arguments </h2>\n",
    "            {params.to_html()}\n",
    "            \"\"\", file=f)\n",
    "\n",
    "def shift_to_other(this, other, this_range=None, this_center=None):\n",
    "    u = other.mean()\n",
    "    r = other.std()#other.max()-other.min()\n",
    "\n",
    "    if this_range is None:\n",
    "        this_range = this.std()#this.max()-this.min()\n",
    "\n",
    "    if this_center is None:\n",
    "        this_center = this.mean()\n",
    "    return (this-this_center)/(this_range)*r+u\n",
    "\n",
    "perf_col = performance_col\n",
    "perf_df = combined_df[perf_col]\n",
    "exclude = ['performance', 'count']\n",
    "if drop_modality:\n",
    "    exclude.append(\"Modality_DICOM\")\n",
    "other_cols = column_xs(combined_df, exclude=exclude)\n",
    "\n",
    "other_df = combined_df[other_cols]\n",
    "extra_valids = pd.DataFrame(columns=other_df.columns)\n",
    "extra_perf = pd.DataFrame(columns=perf_df.name)\n",
    "\n",
    "extra_perf\n",
    "cxs = column_xs(other_df, include=stat)\n",
    "stats = pd.concat([other_df[cxs].dropna(axis=1), extra_valids[cxs].dropna(axis=1)], axis=0).sort_index()\n",
    "\n",
    "\n",
    "stats = stats.loc[standardize_ix]\n",
    "\n",
    "print(len(stats))\n",
    "stats = stats.agg([\"mean\", \"std\"])\n",
    "\n",
    "\n",
    "stats.T\n",
    "\n",
    "otherstd = other_df[cxs].copy()\n",
    "\n",
    "# cannot divide by zero\n",
    "std0 = stats.loc['std'] == 0\n",
    "stats.loc[\"std\", stats.loc['std'] == 0] = 1\n",
    "otherstd = (otherstd-stats.loc['mean'])/(stats.loc[\"std\"])\n",
    "errorstd = (error_df[cxs]-stats.loc['mean'])/(stats.loc[\"std\"])\n",
    "bad_cols = otherstd.columns[otherstd.isnull().max(axis=0)].tolist()\n",
    "\n",
    "\n",
    "print(bad_cols)\n",
    "\n",
    "vae_cols = [c for c in list(otherstd) if \"mu.\" in c[0]]\n",
    "score_cols = [c for c in list(otherstd) if \"activation.\" in c[0]]\n",
    "metadata_cols = sorted(set(otherstd).difference(vae_cols).difference(score_cols))\n",
    "\n",
    "if clip is not None:\n",
    "  otherstd = otherstd.clip(-1*clip, clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "x = pd.date_range(combined_df.index.min(), combined_df.index.max())\n",
    "yp = perf_df.reindex(x)\n",
    "perf_error_df = error_df[perf_col].reindex(x)\n",
    "\n",
    "all_corr_df = correlate_performance(yp.rename('auroc'), otherstd)\n",
    "all_ig_df = mutual_info_performance(yp.rename('auroc'), otherstd, bins=25)\n",
    "\n",
    "m_ = all_ig_df.to_frame().join(all_corr_df.abs().rename('abs(corr)'))\n",
    "m_ = m_.join(m_.mean(axis=1).rename('mean[abs(corr),info_gain]'))\n",
    "m_ = m_.assign(no_weights=1)\n",
    "m_ = m_.fillna(0)\n",
    "m_.sort_values(by='mean[abs(corr),info_gain]', ascending=False).head(20)\n",
    "\n",
    "true_counts = combined_df_o['count'].droplevel([0, 1], axis=1)['obs']\n",
    "count_df = combined_df['count'].reindex(x)\n",
    "dates = {\n",
    "    # \"Lat. Added\": run_row['nonfrontal_add_date'],\n",
    "        #  \"Frontal Removed\": run_row['frontal_remove_date'],\n",
    "        #  \"Peds Added\": run_row['peds_start_date'],\n",
    "        #  \"Peds Stop\": run_row['peds_end_date'],\n",
    "         \"Val Start\": settings.PADCHEST_SPLIT_DATES[0],\n",
    "         \"Test Start\": settings.PADCHEST_SPLIT_DATES[1],\n",
    "         }\n",
    "\n",
    "import json\n",
    "try:\n",
    "    mods = json.loads(run_row.get('label_modifiers'))\n",
    "except:\n",
    "    mods = {}\n",
    "for label, (pct, start_date, end_date) in mods.items():\n",
    "    if start_date:\n",
    "        dates[f\"{label}={pct:.0%} Start\"] = start_date\n",
    "\n",
    "        # if end_date:\n",
    "        #     dates[f\"{label}={pct:.0%} End\"] = end_date \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = m_.copy()\n",
    "\n",
    "yp = yp.reindex(x)\n",
    "otherstd = otherstd.reindex(x)\n",
    "counts = combined_df['count'].iloc[:, 0].reindex(x)\n",
    "counts2 = true_counts.reindex(x)\n",
    "\n",
    "#collect_corr(y, yp, name, when, weights_name, start_date=None, end_date=None)\n",
    "\n",
    "fh = FigureHelper(x)\n",
    "fh.add_trace(y=combined_df['count'].iloc[:, 0], name=\"Num Samples (used)\", line={\"color\": \"green\"}, row=4, col=1)\n",
    "fh.add_trace(y=combined_df['count'].iloc[:, 0], name=\"Num Samples (used)\", kind=go.Bar, row=4, col=1)\n",
    "fh.add_trace(y=true_counts, name=\"Num Samples (obs)\", line={\"color\": \"orange\"}, row=4, col=1)\n",
    "fh.add_trace(y=true_counts, name=\"Num Samples (obs)\", kind=go.Bar, row=4, col=1)\n",
    "fh.add_trace(y=smooth(yp), name=\"AUROC\", connectgaps=False, line={\"color\": \"blue\"}, \n",
    "             yu=smooth(yp+perf_error_df), \n",
    "             yl=smooth(yp-perf_error_df),\n",
    "             row=1, col=1)\n",
    "\n",
    "# fh.add_trace(y=smooth(combined_df[congruency_measure_col]), row=2, name='Data Congruency (True)')\n",
    "\n",
    "corrs = []\n",
    "corrs.append(collect_corr(counts,yp, \"num sampled (used)\", \"Everything\", \"None\"))\n",
    "corrs.append(collect_corr(counts,yp, \"num sampled (used)\", \"Validation\", \"None\",\n",
    "                            start_date=settings.PADCHEST_SPLIT_DATES[0], end_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "corrs.append(collect_corr(counts,yp, \"num sampled (used)\", \"Test\", \"None\",\n",
    "                        start_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "corrs.append(collect_corr(counts,yp, \"num sampled (used)\", \"First Year of Test\", \"None\",\n",
    "                        start_date=settings.PADCHEST_SPLIT_DATES[1], end_date=\"2014-12-31\"))\n",
    "\n",
    "corrs.append(collect_corr(counts2,yp, \"num sampled (obs)\", \"Everything\",\"None\"))\n",
    "corrs.append(collect_corr(counts2,yp, \"num sampled (obs)\", \"Validation\", \"None\",\n",
    "                            start_date=settings.PADCHEST_SPLIT_DATES[0], end_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "corrs.append(collect_corr(counts2,yp, \"num sampled (obs)\", \"Test\", \"None\",\n",
    "                        start_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "corrs.append(collect_corr(counts2,yp, \"num sampled (obs)\", \"First Year of Test\", \"None\",\n",
    "                        start_date=settings.PADCHEST_SPLIT_DATES[1], end_date=\"2014-12-31\"))\n",
    "\n",
    "errorstd = errorstd[otherstd.columns]\n",
    "\n",
    "for i, name in enumerate(m_):\n",
    "    weights = m_[name].sort_values(ascending=False)\n",
    "    # weights = weights.iloc[:5]\n",
    "    y = -w_avg(otherstd.reindex(x), weights=weights.to_dict())\n",
    "    ystd = -w_avg(errorstd.reindex(x), weights=weights.to_dict())\n",
    "    fh.add_trace(y=smooth(y),\n",
    "                        # customdata=smooth(yo),\n",
    "                        showlegend=True, legendgroup=name,\n",
    "                        name=name, line={\"width\": 1},  \n",
    "                        connectgaps=False, row=2, col=1)\n",
    "    \n",
    "    corrs.append(collect_corr(y,yp, \"All Unified\", \"Everything\", name))\n",
    "    corrs.append(collect_corr(y,yp, \"All Unified\", \"Validation\", name,\n",
    "                              start_date=settings.PADCHEST_SPLIT_DATES[0], end_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "    corrs.append(collect_corr(y,yp, \"All Unified\", \"Test\", name,\n",
    "                            start_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "    corrs.append(collect_corr(y,yp, \"All Unified\", \"First Year of Test\", name,\n",
    "                            start_date=settings.PADCHEST_SPLIT_DATES[1], end_date=\"2014-12-31\"))\n",
    "\n",
    "\n",
    "corr_df = pd.DataFrame(corrs).sort_values('when')\n",
    "if show_corr:\n",
    "    display(corr_df)\n",
    "\n",
    "\n",
    "fig = fh.make_fig(shared_xaxes=True, vertical_spacing=0.01, row_heights=[.2, .2, .2, .1])\n",
    "add_dates(fig, dates, line_y=1.05)\n",
    "fig.update_xaxes(showspikes=True, spikecolor=\"black\", spikesnap=\"cursor\", spikemode=\"across\", spikethickness=1)\n",
    "fig.update_layout(spikedistance=1000)\n",
    "fig.update_layout(height=800)\n",
    "fig.update_xaxes(range=[graph_start, graph_end])\n",
    "fig.update_layout(barmode='overlay')\n",
    "fig.update_layout(font=font)\n",
    "fig.show()\n",
    "\n",
    "if write_html: \n",
    "    with open(fn, 'a') as f:\n",
    "        fig_html = fig.to_html()\n",
    "        print(f\"<h2>Full Unified</h2>\", file=f)\n",
    "        if show_corr:\n",
    "            for w, grp in corr_df.groupby('when'):\n",
    "                print(f\"<strong>{w}</strong>{grp.to_html()}\", file=f)\n",
    "        print(fig_html, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_cols = column_xs(combined_df, ['support'])\n",
    "count_cols = [c for c in count_cols if 'avg' not in c[1]]\n",
    "label_counts = combined_df[count_cols]\n",
    "label_counts.columns = [c[1] for c in label_counts.columns]\n",
    "num_samples = combined_df['count'].iloc[:, 0]\n",
    "label_rates = label_counts.div(num_samples, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "auroc_cols = column_xs(combined_df, ['auroc'])\n",
    "precision_cols = column_xs(combined_df, ['precision'])\n",
    "recall_cols = column_xs(combined_df, ['recall'])\n",
    "f1_cols = column_xs(combined_df, ['f1-score'])\n",
    "support_cols = column_xs(combined_df, ['support'])\n",
    "\n",
    "cols_ = [auroc_cols, recall_cols, precision_cols, f1_cols, support_cols]\n",
    "fig = make_subplots(rows=len(cols_), cols=1, shared_xaxes=True, vertical_spacing=0.01)\n",
    "\n",
    "names = sorted(set([c[1] for c in itertools.chain(*cols_)]), key=lambda x: 'avg' in x)\n",
    "colors = px.colors.qualitative.Plotly\n",
    "dashes = ['solid', 'dash', 'dotted']\n",
    "\n",
    "lines = {}\n",
    "for name, spec in zip(names, itertools.product(dashes, colors)):\n",
    "    lines[name] = {'color': spec[1], 'dash': spec[0]}\n",
    "\n",
    "visited = set()\n",
    "for r, cols__ in enumerate(cols_, 1):\n",
    "    for c in cols__:\n",
    "        ypp = combined_df[c].reindex(x)\n",
    "        line = lines[c[1]]\n",
    "        showlegend = not c[1] in visited\n",
    "        visited.add(c[1])\n",
    "        fig.add_trace(go.Scatter(x=x, y=smooth(ypp), showlegend=showlegend, legendgroup=c[1],\n",
    "                name=c[1], hovertemplate=\"%{y: .5f}\", connectgaps=False, line=line), row=r, col=1)\n",
    "    fig.update_yaxes(title_text=c[-1], row=r, col=1)\n",
    "add_dates(fig, dates, 1.025)\n",
    "\n",
    "fig.update_layout(title=f\"Peformance\")\n",
    "fig.update_layout(hovermode=\"x unified\")\n",
    "fig.update_layout(height=300*len(cols_))\n",
    "fig.update_xaxes(range=[graph_start, graph_end])\n",
    "fig.update_layout(font=font)\n",
    "fig.show()\n",
    "\n",
    "if write_html:\n",
    "    fig_html = fig.to_html()\n",
    "    with open(fn, 'a') as f:\n",
    "        print(f\"<h2>Performance</h2>\", file=f)\n",
    "        print(fig_html, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_w = \"no_weights\"\n",
    "\n",
    "fh = FigureHelper(x)\n",
    "fh.add_trace(y=smooth(yp), name=\"AUROC\", connectgaps=False, line={\"color\": \"blue\"}, yu=smooth(yp+perf_error_df), yl=smooth(yp-perf_error_df), row=1, col=1)\n",
    "# fh.add_trace(y=smooth(combined_df[congruency_measure_col]), row=2, name='Data Congruency (True)')\n",
    "corrs = []\n",
    "run_row['peds_weight'] = 0\n",
    "if not float(run_row['peds_weight']):\n",
    "    xcols = zip([\"metadata\", \"vae\", \"score\", \"vae+score\", \"metadate+vae+score\"],  [metadata_cols, vae_cols, score_cols, vae_cols+score_cols, vae_cols+score_cols+metadata_cols])\n",
    "else:\n",
    "    xcols = zip([\"vae\", \"score\", \"vae+score\"],  [vae_cols, score_cols, vae_cols+score_cols])\n",
    "\n",
    "for row, (name_, cols) in enumerate(xcols, 1):\n",
    "    for i, name in enumerate([other_w]):\n",
    "        otherstd_ = otherstd[cols]\n",
    "        weights = m[name].sort_values(ascending=False)\n",
    "        yo = -w_avg(otherstd_.loc[x], weights=weights.to_dict())\n",
    "        \n",
    "        fh.add_trace(y=smooth(yo), name=name_, line={\"width\": 1},  connectgaps=False, row=2, col=1)\n",
    "        \n",
    "        corrs.append(collect_corr(y,yo, name_, \"Everything\", name))\n",
    "        corrs.append(collect_corr(y,yo, name_, \"Validation\", name,\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[0], end_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "        corrs.append(collect_corr(y,yo, name_, \"Test\", name,\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "        corrs.append(collect_corr(y,yo, name_, \"First Year of Test\", name,\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[1], end_date=\"2014-12-31\"))\n",
    "\n",
    "\n",
    "fig = fh.make_fig(shared_xaxes=True, vertical_spacing=0.01)\n",
    "add_dates(fig, dates, 1.08)\n",
    "\n",
    "\n",
    "fig.update_layout(title=f\"Level 1 Metrics\")\n",
    "fig.update_xaxes(showspikes=True, spikecolor=\"black\", spikesnap=\"cursor\", spikemode=\"across\", spikethickness=1)\n",
    "fig.update_layout(spikedistance=1000)\n",
    "fig.update_layout(height=600)\n",
    "fig.update_xaxes(range=[graph_start, graph_end])\n",
    "fig.update_layout(barmode='overlay')\n",
    "corr_df = pd.DataFrame(corrs).sort_values('when')\n",
    "display(corr_df)\n",
    "fig.show()\n",
    "\n",
    "fig_html = fig.to_html()\n",
    "\n",
    "if write_html:\n",
    "    with open(fn, 'a') as f:\n",
    "        print(f\"<h2>Level 1 Unified</h2>\", file=f)\n",
    "        for w, grp in corr_df.groupby('when'):\n",
    "            print(f\"<strong>{w}</strong>{grp.to_html()}\", file=f)\n",
    "        print(fig_html, file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_corr = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = FigureHelper(x, dashes=['solid', 'dot', 'dash', 'longdash', 'dashdot', 'longdashdot'])\n",
    "# fh.add_trace(y=smooth(yp), name=\"AUROC\", connectgaps=False, line={\"color\": \"blue\"}, yu=smooth(yp+perf_error_df), yl=smooth(yp-perf_error_df), row=1, col=1)\n",
    "# fh.add_trace(y=smooth(combined_df[congruency_measure_col]), row=2, name='Data Congruency (True)')\n",
    "corrs = []\n",
    "\n",
    "def partition(l, n):\n",
    "    return [l[i:i + n] for i in range(0, len(l), n)]\n",
    "\n",
    "cols = score_cols\n",
    "otherstd_ = otherstd[cols]\n",
    "cols_ = [column_xs(otherstd_, include='distance'), column_xs(otherstd_, include='pval'), ]\n",
    "cols_ = [c for c in cols_ if len(c)]\n",
    "\n",
    "for col in label_rates.columns:\n",
    "    fh.add_trace(y=smooth(label_rates[col]), name=str(col), connectgaps=False, row=1, col=1)\n",
    "\n",
    "print(len(cols_))\n",
    "\n",
    "for row, cols in enumerate(cols_, 2):\n",
    "    for c in cols:\n",
    "        yo = -otherstd[c]\n",
    "        fh.add_trace(y=smooth(yo), name=str(c), connectgaps=False, row=row, col=1)\n",
    "        \n",
    "        corrs.append(collect_corr(y,yo, str(c), \"Everything\", 'N/A'))\n",
    "        corrs.append(collect_corr(y,yo, str(c), \"Validation\", 'N/A',\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[0], end_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "        corrs.append(collect_corr(y,yo, str(c), \"Test\", 'N/A',\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "        corrs.append(collect_corr(y,yo, str(c), \"First Year of Test\", 'N/A',\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[1], end_date=\"2014-12-31\"))\n",
    "\n",
    "if not float(run_row['peds_weight']):     \n",
    "    fig = fh.make_fig(shared_xaxes=True, vertical_spacing=0.05)\n",
    "    add_dates(fig, dates, 1.05)\n",
    "\n",
    "    fig.update_layout(title=f\"Score\")\n",
    "    fig.update_xaxes(showspikes=True, spikecolor=\"black\", spikesnap=\"cursor\", spikemode=\"across\", spikethickness=1)\n",
    "    fig.update_layout(spikedistance=1000)\n",
    "    fig.update_layout(height=200*(len(cols_)+1))\n",
    "    # fig.update_layout(yaxis1=dict(range=[.6, 1]))\n",
    "    fig.update_layout(yaxis1=dict(range=[0, 1], title=\"label rate\"))\n",
    "    fig.update_layout(yaxis2=dict(range=[-10, 1], title=\"distance\"))\n",
    "    if len(cols_) > 2:\n",
    "        fig.update_layout(yaxis3=dict(range=[-10, 1], title=\"pval\"))\n",
    "    fig.update_xaxes(range=[graph_start, graph_end])\n",
    "    \n",
    "    fig.update_layout(font=font)\n",
    "    fig.update_layout(barmode='overlay')\n",
    "\n",
    "    if show_corr:\n",
    "        corr_df = pd.DataFrame(corrs)\n",
    "        display(corr_df)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "    fig_html = fig.to_html()\n",
    "    if write_html: \n",
    "        with open(fn, 'a') as f:\n",
    "            print(f\"<h2>Score</h2>\", file=f)\n",
    "            if show_corr:\n",
    "                for w, grp in corr_df.groupby('when'):\n",
    "                    print(f\"<strong>{w}</strong>{grp.to_html()}\", file=f)\n",
    "            print(fig_html, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = FigureHelper(x, dashes=['solid', 'dot', 'dash', 'longdash', 'dashdot', 'longdashdot'])\n",
    "fh.add_trace(y=smooth(yp), name=\"AUROC\", connectgaps=False, line={\"color\": \"blue\"}, yu=smooth(yp+perf_error_df), yl=smooth(yp-perf_error_df), row=1, col=1)\n",
    "# fh.add_trace(y=smooth(combined_df[congruency_measure_col]), row=2, name='Data Congruency (True)')\n",
    "corrs = []\n",
    "\n",
    "def partition(l, n):\n",
    "    return [l[i:i + n] for i in range(0, len(l), n)]\n",
    "\n",
    "cols = metadata_cols\n",
    "otherstd_ = otherstd[cols]\n",
    "cols_chi2 = column_xs(otherstd_, include='chi2')\n",
    "otherstd_ = otherstd[cols_chi2]\n",
    "cols_ = partition(cols_chi2, 12)\n",
    "print(len(cols_))\n",
    "\n",
    "for row, cols in enumerate(cols_, 2):\n",
    "    for c in cols:\n",
    "        yo = -otherstd[c]\n",
    "        fh.add_trace(y=smooth(yo), name=str(c), connectgaps=False, row=row, col=1)\n",
    "        \n",
    "        corrs.append(collect_corr(y,yo, str(c), \"Everything\", 'N/A'))\n",
    "        corrs.append(collect_corr(y,yo, str(c), \"Validation\", 'N/A',\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[0], end_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "        corrs.append(collect_corr(y,yo, str(c), \"Test\", 'N/A',\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "        corrs.append(collect_corr(y,yo, str(c), \"First Year of Test\", 'N/A',\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[1], end_date=\"2014-12-31\"))\n",
    "\n",
    "if not float(run_row['peds_weight']):     \n",
    "    fig = fh.make_fig(shared_xaxes=True, vertical_spacing=0.01)\n",
    "    add_dates(fig, dates, 1.05)\n",
    "\n",
    "    fig.update_layout(title=f\"Metadata Categorical\")\n",
    "    fig.update_xaxes(showspikes=True, spikecolor=\"black\", spikesnap=\"cursor\", spikemode=\"across\", spikethickness=1)\n",
    "    fig.update_layout(spikedistance=1000)\n",
    "    fig.update_layout(height=200*(len(cols_)+2))\n",
    "    fig.update_xaxes(range=[graph_start, graph_end])\n",
    "    fig.update_layout(font=font)\n",
    "    fig.update_layout(barmode='overlay')\n",
    "\n",
    "    if show_corr:\n",
    "        corr_df = pd.DataFrame(corrs)\n",
    "        display(corr_df)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "    fig_html = fig.to_html()\n",
    "    if write_html: \n",
    "        with open(fn, 'a') as f:\n",
    "            print(f\"<h2>Metadata Categorical</h2>\", file=f)\n",
    "            if show_corr:\n",
    "                for w, grp in corr_df.groupby('when'):\n",
    "                    print(f\"<strong>{w}</strong>{grp.to_html()}\", file=f)\n",
    "            print(fig_html, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = FigureHelper(x, dashes=['solid', 'dot', 'dash', 'longdash', 'dashdot', 'longdashdot'])\n",
    "fh.add_trace(y=smooth(yp), name=\"AUROC\", connectgaps=False, line={\"color\": \"blue\"}, yu=smooth(yp+perf_error_df), yl=smooth(yp-perf_error_df), row=1, col=1)\n",
    "fh.add_trace(y=smooth(combined_df[congruency_measure_col]), row=2, name='Data Congruency (True)')\n",
    "corrs = []\n",
    "\n",
    "def partition(l, n):\n",
    "    return [l[i:i + n] for i in range(0, len(l), n)]\n",
    "\n",
    "cols = metadata_cols\n",
    "otherstd_ = otherstd[cols]\n",
    "cols_chi2 = column_xs(otherstd_, include='ks')\n",
    "otherstd_ = otherstd[cols_chi2]\n",
    "cols_ = partition(cols_chi2, 14)\n",
    "print(len(cols_chi2))\n",
    "\n",
    "for row, cols in enumerate(cols_, 3):\n",
    "    for c in cols:\n",
    "        yo = -otherstd[c]\n",
    "        fh.add_trace(y=smooth(yo), name=str(c), connectgaps=False, row=row, col=1)\n",
    "        \n",
    "        corrs.append(collect_corr(y,yo, str(c), \"Everything\", 'N/A'))\n",
    "        corrs.append(collect_corr(y,yo, str(c), \"Validation\", 'N/A',\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[0], end_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "        corrs.append(collect_corr(y,yo, str(c), \"Test\", 'N/A',\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "        corrs.append(collect_corr(y,yo, str(c), \"First Year of Test\", 'N/A',\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[1], end_date=\"2014-12-31\"))\n",
    "if show_corr:\n",
    "    corr_df = pd.DataFrame(corrs)\n",
    "    display(corr_df)\n",
    "\n",
    "if not float(run_row['peds_weight']):\n",
    "    fig = fh.make_fig(shared_xaxes=True, vertical_spacing=0.01)\n",
    "    add_dates(fig, dates, 1.08)\n",
    "\n",
    "    fig.update_layout(title=f\"Metadata Real Valued\")\n",
    "    fig.update_xaxes(showspikes=True, spikecolor=\"black\", spikesnap=\"cursor\", spikemode=\"across\", spikethickness=1)\n",
    "    fig.update_layout(spikedistance=1000)\n",
    "    fig.update_layout(height=200*(len(cols_)+2))\n",
    "    fig.update_xaxes(range=[graph_start, graph_end])\n",
    "    fig.update_layout(font=font)\n",
    "    fig.update_layout(barmode='overlay')\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "    fig_html = fig.to_html()\n",
    "    if write_html: \n",
    "        with open(fn, 'a') as f:\n",
    "            print(f\"<h2>Metadata Real Valued</h2>\", file=f)\n",
    "            if show_corr:\n",
    "                for w, grp in corr_df.groupby('when'):\n",
    "                    print(f\"<strong>{w}</strong>{grp.to_html()}\", file=f)\n",
    "            print(fig_html, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = FigureHelper(x, dashes=['solid', 'dot', 'dash', 'longdash', 'dashdot', 'longdashdot'])\n",
    "fh.add_trace(y=smooth(yp), name=\"AUROC\", connectgaps=False, line={\"color\": \"blue\"}, yu=smooth(yp+perf_error_df), yl=smooth(yp-perf_error_df), row=1, col=1)\n",
    "# fh.add_trace(y=smooth(combined_df[congruency_measure_col]), row=2, name='Data Congruency (True)')\n",
    "corrs = []\n",
    "\n",
    "def partition(l, n):\n",
    "    return [l[i:i + n] for i in range(0, len(l), n)]\n",
    "\n",
    "\n",
    "cols = vae_cols\n",
    "o = other_df[cols].loc[settings.PADCHEST_SPLIT_DATES[1]:].swaplevel(0, 2, axis=1)[['distance']].swaplevel(0, 2, axis=1)\n",
    "colss = o.max(axis=0).sort_values(ascending=False).head(12).index.tolist()\n",
    "cols_ = partition(colss, 12)\n",
    "\n",
    "\n",
    "for row, cols in enumerate(cols_, 2):\n",
    "    for c in cols:\n",
    "        yo = -otherstd[c]\n",
    "        fh.add_trace(y=smooth(yo), name=str(c), connectgaps=False, row=row, col=1)\n",
    "        \n",
    "        corrs.append(collect_corr(y,yo, str(c), \"Everything\", 'N/A'))\n",
    "        corrs.append(collect_corr(y,yo, str(c), \"Validation\", 'N/A',\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[0], end_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "        corrs.append(collect_corr(y,yo, str(c), \"Test\", 'N/A',\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[1]))\n",
    "        corrs.append(collect_corr(y,yo, str(c), \"First Year of Test\", 'N/A',\n",
    "                                start_date=settings.PADCHEST_SPLIT_DATES[1], end_date=\"2014-12-31\"))\n",
    "        \n",
    "fig = fh.make_fig(shared_xaxes=True, vertical_spacing=0.01)\n",
    "add_dates(fig, dates, 1.08)\n",
    "\n",
    "fig.update_layout(title=f\"VAE Mu (top {len(colss)})\")\n",
    "fig.update_xaxes(showspikes=True, spikecolor=\"black\", spikesnap=\"cursor\", spikemode=\"across\", spikethickness=1)\n",
    "fig.update_layout(spikedistance=1000)\n",
    "fig.update_layout(height=200*(len(cols_)+2))\n",
    "fig.update_xaxes(range=[settings.PADCHEST_SPLIT_DATES[1], graph_end])\n",
    "fig.update_layout(barmode='overlay')\n",
    "fig.update_layout(font=font)\n",
    "corr_df = pd.DataFrame(corrs).sort_values('when')\n",
    "if show_corr:\n",
    "    display(corr_df)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig_html = fig.to_html()\n",
    "if write_html: \n",
    "    with open(fn, 'a') as f:\n",
    "        print(f\"<h2>VAE Mu (top {len(colss)})</h2>\", file=f)\n",
    "        if show_corr:\n",
    "            for w, grp in corr_df.groupby('when'):\n",
    "                print(f\"<strong>{w}</strong>{grp.to_html()}\", file=f)\n",
    "        print(fig_html, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_df2['Link'] = [f\"\"\"<a href=\"{name}/index.html\" disabled=>Graphs</a>\"\"\" if html_top_dir.joinpath(name).exists() else \"N/A\" for name in arg_df2.index]\n",
    "\n",
    "\n",
    "with open(html_top_dir.joinpath(\"index.html\"), 'w') as f:\n",
    "        print(\"\"\"\n",
    "            <style>\n",
    "            table {\n",
    "            font-family: arial, sans-serif;\n",
    "            border-collapse: collapse;\n",
    "            width: 80%;\n",
    "            }\n",
    "\n",
    "            td, th {\n",
    "            border: 1px solid #dddddd;\n",
    "            text-align: left;\n",
    "            padding: 8px;\n",
    "            }\n",
    "\n",
    "            tr:nth-child(even) {\n",
    "            background-color: #dddddd;\n",
    "            }\n",
    "            </style>\n",
    "        \"\"\", file=f)\n",
    "        print(f\"Generated: {datetime.datetime.now()}\", file=f)\n",
    "        print(arg_df2.to_html(escape=False), file=f)\n",
    "        print(fix_links_script, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_html(child):\n",
    "    if child.is_file(): return\n",
    "    html_files = []\n",
    "    html_folders = []\n",
    "    if child.parent.joinpath('index.html').exists():\n",
    "        html_folders.append(\"..\")\n",
    "    for html_file in child.iterdir():\n",
    "        n = html_file.relative_to(child)\n",
    "        if html_file.is_file() and not str(html_file).endswith('index.html'):\n",
    "            html_files.append(n)\n",
    "        elif html_file.joinpath('index.html').exists():\n",
    "            html_folders.append(n)\n",
    "    \n",
    "    \n",
    "    html = \"folders: <ul>\"\n",
    "    for n in html_folders:\n",
    "            html += f\"\"\"\n",
    "            <li><a href=\"{n}/index.html\">{n}</a></li>\n",
    "            \"\"\"\n",
    "    html += \"</ul>\"\n",
    "    html += \"files:<ul>\"\n",
    "    for n in html_files:\n",
    "            html += f\"\"\"\n",
    "            <li><a href=\"{n}\">{n}</a></li>\n",
    "            \"\"\"\n",
    "    html += \"</ul>\"\n",
    "    with open(child.joinpath('index.html'), 'w') as f:\n",
    "        print(html, file=f)\n",
    "        print(fix_links_script, file=f)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_index_html(html_top_dir.parent.joinpath('vae[all-data]'))\n",
    "create_index_html(html_top_dir.parent)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in html_top_dir.iterdir():\n",
    "    create_index_html(child)\n",
    "    \n",
    "            \n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40209cfd1e49aba1e20a3908f9a243f43b2ed73034fd3a81730d62124bbdcdae"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
